{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Target","metadata":{}},{"cell_type":"markdown","source":"- Solve a classification problem with deep neural networks (DNNs).\n- Understand recursive neural networks (RNNs).","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport argparse\nfrom tqdm import tqdm\n\nimport numpy as np\n\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import DataLoader\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T04:27:45.827542Z","iopub.execute_input":"2024-06-29T04:27:45.828311Z","iopub.status.idle":"2024-06-29T04:27:45.833494Z","shell.execute_reply.started":"2024-06-29T04:27:45.828277Z","shell.execute_reply":"2024-06-29T04:27:45.832252Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"# Helper function","metadata":{}},{"cell_type":"markdown","source":"- `random.seed(seed)`: Sets the seed for **Python's built-in** random module.\n- `np.random.seed(seed)`: Sets the seed for **NumPy's** random number generator.\n- `torch.manual_seed(seed)`: Sets the seed for **PyTorch on the CPU**.\n- `torch.cuda.manual_seed(seed)`: Sets the seed for the **current GPU**.\n- `torch.cuda.manual_seed_all(seed)`: Sets the seed for **all GPUs**.\n- `torch.backends.cudnn.benchmark = False`: Disables the CuDNN benchmark mode.\n- `torch.backends.cudnn.deterministic = True`: Forces CuDNN to use deterministic algorithms, which helps in reproducibility.","metadata":{}},{"cell_type":"markdown","source":"`torch.backends.cudnn.benchmark` 是 PyTorch 的一個設置，用來啟用或禁用 CuDNN 的基準模式：\n\n- True：讓 CuDNN 尋找最佳的卷積算法，可能提高訓練速度，但結果可能不可重現。\n- False：使用固定的算法，確保結果可重現，通常用於測試和比較實驗結果。\n\n**在追求可重現性時，可設置為 False**","metadata":{}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmarkbe = False\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:28:36.668294Z","iopub.execute_input":"2024-06-29T04:28:36.668694Z","iopub.status.idle":"2024-06-29T04:28:36.674499Z","shell.execute_reply.started":"2024-06-29T04:28:36.668661Z","shell.execute_reply":"2024-06-29T04:28:36.673320Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"- 函數：\n\n`load_feat(path)`：\n\n    從指定路徑加載 PyTorch 張量。\n\n`shift(x, n)`：\n\n    將張量 x 向左或向右移動 n 個位置。\n    根據移動方向用第一或最後一個元素填充。\n\n`concat_feat(x, concat_n)`：\n\n    在每個幀周圍串聯 concat_n 幀。\n    確保 concat_n 是奇數。\n    使用 shift 函數來正確調整每個幀。\n\n- 主函數：\n`preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8)`：\n\n    用於訓練、驗證或測試的數據預處理。\n    加載和串聯特徵。\n    根據 train_ratio 將數據拆分為訓練集和驗證集。\n    \n    - 步驟：\n\n        - 加載數據：\n\n            讀取標籤並拆分數據集。\n            使用 load_feat 加載特徵文件。\n            特徵串聯：\n\n            使用 concat_feat 串聯幀以提供上下文。\n            數據準備：\n\n            為特徵 (X) 和標籤 (y) 準備張量。\n\n        - 輸出：\n\n            返回處理好的訓練/驗證集的特徵和標籤張量，或僅返回測試集的特徵。\n            關鍵點：\n            concat_nframes 必須是奇數以確保對稱上下文。\n            train_ratio 控制訓練和驗證之間的拆分比例。\n            預定義的最大長度 (max_len) 保證了內存的高效分配，可以根據需要調整。\n            使用 tqdm 來追踪進度。","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"def load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x: torch.Tensor, n: int) -> torch.Tensor:\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x: torch.Tensor, concat_n: int):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:27:19.837902Z","iopub.execute_input":"2024-06-29T04:27:19.838366Z","iopub.status.idle":"2024-06-29T04:27:19.849281Z","shell.execute_reply.started":"2024-06-29T04:27:19.838331Z","shell.execute_reply":"2024-06-29T04:27:19.848154Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{}},{"cell_type":"code","source":"test = torch.Tensor([[1,2,3],\n                     [4,5,6],\n                     [7,8,9],\n                     [10,11,12]])\n\nshift(test,2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.513179Z","iopub.execute_input":"2024-06-29T03:17:51.514108Z","iopub.status.idle":"2024-06-29T03:17:51.522560Z","shell.execute_reply.started":"2024-06-29T03:17:51.514070Z","shell.execute_reply":"2024-06-29T03:17:51.521541Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"tensor([[ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.],\n        [10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.704742Z","iopub.execute_input":"2024-06-29T03:17:51.705665Z","iopub.status.idle":"2024-06-29T03:17:51.711800Z","shell.execute_reply.started":"2024-06-29T03:17:51.705630Z","shell.execute_reply":"2024-06-29T03:17:51.710743Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 3])"},"metadata":{}}]},{"cell_type":"code","source":"test.repeat(1, 3).shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.907636Z","iopub.execute_input":"2024-06-29T03:17:51.908016Z","iopub.status.idle":"2024-06-29T03:17:51.914929Z","shell.execute_reply.started":"2024-06-29T03:17:51.907983Z","shell.execute_reply":"2024-06-29T03:17:51.913865Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 9])"},"metadata":{}}]},{"cell_type":"code","source":"seq_len, feature_len = test.size(0), test.size(1) # 4*3\ntest = test.repeat(1, 3) # 4*9\ntest.view(seq_len, 3, feature_len) # 4 *3 *3","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:52.092907Z","iopub.execute_input":"2024-06-29T03:17:52.093945Z","iopub.status.idle":"2024-06-29T03:17:52.102385Z","shell.execute_reply.started":"2024-06-29T03:17:52.093906Z","shell.execute_reply":"2024-06-29T03:17:52.101360Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 1.,  2.,  3.],\n         [ 1.,  2.,  3.]],\n\n        [[ 4.,  5.,  6.],\n         [ 4.,  5.,  6.],\n         [ 4.,  5.,  6.]],\n\n        [[ 7.,  8.,  9.],\n         [ 7.,  8.,  9.],\n         [ 7.,  8.,  9.]],\n\n        [[10., 11., 12.],\n         [10., 11., 12.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"test = test.view(seq_len, 3, feature_len).permute(1, 0, 2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:08.953858Z","iopub.execute_input":"2024-06-29T03:18:08.954523Z","iopub.status.idle":"2024-06-29T03:18:08.959533Z","shell.execute_reply.started":"2024-06-29T03:18:08.954484Z","shell.execute_reply":"2024-06-29T03:18:08.958413Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"test  # 3*4*3 permute() rearange tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:10.909438Z","iopub.execute_input":"2024-06-29T03:18:10.910539Z","iopub.status.idle":"2024-06-29T03:18:10.918809Z","shell.execute_reply.started":"2024-06-29T03:18:10.910493Z","shell.execute_reply":"2024-06-29T03:18:10.917673Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"mid = (3 // 2) # 1\nfor r_idx in range(1, mid+1): # 1\n    a = shift(test[mid + r_idx], r_idx)\n    test[mid + r_idx, :] = a\n    print(a)\n\n    b = shift(test[mid - r_idx], -r_idx)\n    test[mid - r_idx, :] = b\n    print(b)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:19:56.502913Z","iopub.execute_input":"2024-06-29T03:19:56.503370Z","iopub.status.idle":"2024-06-29T03:19:56.513391Z","shell.execute_reply.started":"2024-06-29T03:19:56.503335Z","shell.execute_reply":"2024-06-29T03:19:56.512321Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"tensor([[ 4.,  5.,  6.],\n        [ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.]])\ntensor([[1., 2., 3.],\n        [1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"test.permute(1, 0, 2).view(seq_len, 3 * feature_len) # 4*9","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:21:45.364255Z","iopub.execute_input":"2024-06-29T03:21:45.364660Z","iopub.status.idle":"2024-06-29T03:21:45.373197Z","shell.execute_reply.started":"2024-06-29T03:21:45.364628Z","shell.execute_reply":"2024-06-29T03:21:45.372216Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.,  2.,  3.,  1.,  2.,  3.,  4.,  5.,  6.],\n        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n        [ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n        [ 7.,  8.,  9., 10., 11., 12., 10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"def preprocess_data(split: str, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    max_len = 3000000\n    X = torch.empty(max_len, 39 * concat_nframes)\n    if mode == 'train':\n        y = torch.empty(max_len, dtype=torch.long)\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n            label = torch.LongTensor(label_dict[fname])\n\n        X[idx: idx + cur_len, :] = feat\n        if mode == 'train':\n            y[idx: idx + cur_len] = label\n\n        idx += cur_len\n\n    X = X[:idx, :]\n    if mode == 'train':\n        y = y[:idx]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode == 'train':\n        print(y.shape)\n        return X, y\n    else:\n        return X","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:27:23.075946Z","iopub.execute_input":"2024-06-29T04:27:23.076672Z","iopub.status.idle":"2024-06-29T04:27:23.091942Z","shell.execute_reply.started":"2024-06-29T04:27:23.076634Z","shell.execute_reply":"2024-06-29T04:27:23.090836Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{}},{"cell_type":"code","source":"label_dict = {}\nfor line in open(\"/kaggle/input/libraphone/libriphone/train_labels.txt\").readlines():\n    print(len(line))\n    line = line.strip('\\n').split(' ')\n    print(len(line))\n    label_dict[line[0]] = [int(p) for p in line[1:]]\n    print(label_dict)\n    break\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:48:11.979126Z","iopub.execute_input":"2024-06-29T03:48:11.979554Z","iopub.status.idle":"2024-06-29T03:48:11.999084Z","shell.execute_reply.started":"2024-06-29T03:48:11.979520Z","shell.execute_reply":"2024-06-29T03:48:11.998155Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"2121\n841\n{'4830-25898-0031': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 12, 12, 27, 27, 27, 38, 38, 38, 38, 38, 38, 38, 35, 35, 35, 35, 35, 25, 25, 25, 25, 25, 25, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 37, 37, 37, 37, 37, 30, 30, 30, 30, 30, 30, 30, 30, 27, 27, 27, 4, 4, 4, 4, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 37, 37, 37, 37, 37, 37, 14, 14, 14, 14, 14, 14, 14, 4, 4, 4, 4, 4, 4, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 8, 8, 8, 8, 8, 8, 8, 8, 8, 27, 27, 27, 27, 27, 27, 27, 23, 23, 23, 23, 23, 23, 23, 23, 23, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 37, 37, 37, 37, 37, 37, 37, 27, 27, 27, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 35, 35, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40, 30, 30, 30, 30, 30, 30, 30, 30, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 40, 40, 40, 40, 40, 40, 40, 40, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 39, 39, 39, 39, 39, 39, 39, 39, 5, 5, 5, 5, 5, 5, 5, 5, 5, 12, 12, 12, 12, 12, 12, 12, 12, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 26, 26, 26, 26, 26, 26, 26, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 27, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 2, 2, 2, 2, 2, 2, 2, 2, 16, 16, 16, 16, 16, 16, 16, 16, 31, 31, 31, 31, 31, 31, 31, 31, 23, 23, 23, 23, 9, 9, 9, 9, 9, 9, 9, 9, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"split = \"train\"\n\nusage_list = open(\"/kaggle/input/libraphone/libriphone/train_split.txt\").readlines()\nprint(f\"read first: {usage_list[0]}\")\nrandom.shuffle(usage_list)\nprint(f\"After shuffling: {usage_list[0]}\")\ntrain_len = int(len(usage_list) * 0.8)\nusage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\nprint(f\"After train split: {usage_list[0]}\")\nusage_list = [line.strip('\\n') for line in usage_list]\nprint(f\"Strip \\\\n: {usage_list[0]}\")\nprint('[Dataset] - # phone classes: ' + str(41) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:49:30.748076Z","iopub.execute_input":"2024-06-29T03:49:30.748484Z","iopub.status.idle":"2024-06-29T03:49:30.760407Z","shell.execute_reply.started":"2024-06-29T03:49:30.748433Z","shell.execute_reply":"2024-06-29T03:49:30.759330Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"read first: 4830-25898-0031\n\nAfter shuffling: 2989-138028-0022\n\nAfter train split: 2989-138028-0022\n\nStrip \\n: 2989-138028-0022\n[Dataset] - # phone classes: 41, number of utterances for train: 2743\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Dataset\n","metadata":{}},{"cell_type":"code","source":"class LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:27:26.053437Z","iopub.execute_input":"2024-06-29T04:27:26.054426Z","iopub.status.idle":"2024-06-29T04:27:26.060707Z","shell.execute_reply.started":"2024-06-29T04:27:26.054389Z","shell.execute_reply":"2024-06-29T04:27:26.059528Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n        super().__init__()\n\n        self.fc = nn.Sequential(\n            BasicBlock(input_dim, hidden_dim),\n            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:27:27.676256Z","iopub.execute_input":"2024-06-29T04:27:27.676655Z","iopub.status.idle":"2024-06-29T04:27:27.684701Z","shell.execute_reply.started":"2024-06-29T04:27:27.676625Z","shell.execute_reply":"2024-06-29T04:27:27.683632Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{}},{"cell_type":"code","source":"parser = argparse.ArgumentParser(description='設定資料與訓練參數')\n\n# 資料參數\nparser.add_argument('--concat_nframes', type=int, default=3,\n                    help='連接的幀數，n 必須為奇數 (總共 2k+1 = n 幀)')\nparser.add_argument('--train_ratio', type=float, default=0.75,\n                    help='訓練資料比例，其餘將用於驗證')\n\n# 訓練參數\nparser.add_argument('--seed', type=int, default=1213,\n                    help='隨機種子')\nparser.add_argument('--batch_size', type=int, default=512,\n                    help='批次大小')\nparser.add_argument('--num_epoch', type=int, default=10,\n                    help='訓練的 epoch 數量')\nparser.add_argument('--learning_rate', type=float, default=1e-4,\n                    help='學習率')\nparser.add_argument('--model_path', type=str, default='./model.ckpt',\n                    help='模型儲存的路徑')\n\n# 模型參數\nparser.add_argument('--input_dim', type=int, default=39 * 3,\n                    help='模型的輸入維度，不應更改此值')\nparser.add_argument('--hidden_layers', type=int, default=2,\n                    help='隱藏層的層數')\nparser.add_argument('--hidden_dim', type=int, default=64,\n                    help='隱藏層的維度')\n\nargs = parser.parse_args()\n\n# 打印參數設定\nprint('資料參數:')\nprint(f'- 連接的幀數: {args.concat_nframes}')\nprint(f'- 訓練資料比例: {args.train_ratio}')\n\nprint('\\n訓練參數:')\nprint(f'- 隨機種子: {args.seed}')\nprint(f'- 批次大小: {args.batch_size}')\nprint(f'- 訓練 epoch 數量: {args.num_epoch}')\nprint(f'- 學習率: {args.learning_rate}')\nprint(f'- 模型儲存路徑: {args.model_path}')\n\nprint('\\n模型參數:')\nprint(f'- 輸入維度: {args.input_dim}')\nprint(f'- 隱藏層數量: {args.hidden_layers}')\nprint(f'- 隱藏層維度: {args.hidden_dim}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 3              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 512                # batch size\nnum_epoch = 10                   # the number of training epoch\nlearning_rate = 1e-4         # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 2               # the number of hidden layers\nhidden_dim = 64                # the hidden dim","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:27:31.490557Z","iopub.execute_input":"2024-06-29T04:27:31.490937Z","iopub.status.idle":"2024-06-29T04:27:31.496764Z","shell.execute_reply.started":"2024-06-29T04:27:31.490905Z","shell.execute_reply":"2024-06-29T04:27:31.495668Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"same_seeds(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:28:42.289416Z","iopub.execute_input":"2024-06-29T04:28:42.289820Z","iopub.status.idle":"2024-06-29T04:28:42.296956Z","shell.execute_reply.started":"2024-06-29T04:28:42.289791Z","shell.execute_reply":"2024-06-29T04:28:42.296000Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"DEVICE: cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"# preprocess data\ntrain_X, train_y = preprocess_data(split='train',\n                                   feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                                   phone_path='/kaggle/input/libraphone/libriphone',\n                                   concat_nframes=concat_nframes,\n                                   train_ratio=train_ratio)\n\nval_X, val_y = preprocess_data(split='val',\n                               feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                               phone_path='/kaggle/input/libraphone/libriphone',\n                               concat_nframes=concat_nframes,\n                               train_ratio=train_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:29:23.226969Z","iopub.execute_input":"2024-06-29T04:29:23.227378Z","iopub.status.idle":"2024-06-29T04:29:45.542441Z","shell.execute_reply.started":"2024-06-29T04:29:23.227346Z","shell.execute_reply":"2024-06-29T04:29:45.541364Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for train: 2571\n","output_type":"stream"},{"name":"stderr","text":"2571it [00:18, 136.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\ntorch.Size([1588590, 117])\ntorch.Size([1588590])\n[Dataset] - # phone classes: 41, number of utterances for val: 858\n","output_type":"stream"},{"name":"stderr","text":"858it [00:02, 347.73it/s]","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\ntorch.Size([525078, 117])\ntorch.Size([525078])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:30:07.589279Z","iopub.execute_input":"2024-06-29T04:30:07.590224Z","iopub.status.idle":"2024-06-29T04:30:07.594774Z","shell.execute_reply.started":"2024-06-29T04:30:07.590183Z","shell.execute_reply":"2024-06-29T04:30:07.593690Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:30:09.052362Z","iopub.execute_input":"2024-06-29T04:30:09.052773Z","iopub.status.idle":"2024-06-29T04:30:09.486832Z","shell.execute_reply.started":"2024-06-29T04:30:09.052740Z","shell.execute_reply":"2024-06-29T04:30:09.485793Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"3780"},"metadata":{}}]},{"cell_type":"code","source":"# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:32:52.873351Z","iopub.execute_input":"2024-06-29T04:32:52.874328Z","iopub.status.idle":"2024-06-29T04:32:52.879337Z","shell.execute_reply.started":"2024-06-29T04:32:52.874291Z","shell.execute_reply":"2024-06-29T04:32:52.878183Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:31:53.765681Z","iopub.execute_input":"2024-06-29T04:31:53.766306Z","iopub.status.idle":"2024-06-29T04:31:53.931501Z","shell.execute_reply.started":"2024-06-29T04:31:53.766273Z","shell.execute_reply":"2024-06-29T04:31:53.930309Z"},"trusted":true},"execution_count":162,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"torch.Size([512, 117])"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(train_loader))[1].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:31:50.496380Z","iopub.execute_input":"2024-06-29T04:31:50.497052Z","iopub.status.idle":"2024-06-29T04:31:50.666419Z","shell.execute_reply.started":"2024-06-29T04:31:50.497016Z","shell.execute_reply":"2024-06-29T04:31:50.665225Z"},"trusted":true},"execution_count":161,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"torch.Size([512])"},"metadata":{}}]},{"cell_type":"code","source":"# create model, define a loss function, and optimizer\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nbest_acc = 0.0\nfor epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    \n    # training\n    model.train() # set the model to training mode\n    for i, batch in enumerate(tqdm(train_loader)):\n        features, labels = batch\n        features = features.to(device) # 512 * 117\n        labels = labels.to(device)\n        \n        optimizer.zero_grad() \n        outputs = model(features)  # 512 * 41\n        \n        loss = criterion(outputs, labels)\n        loss.backward() \n        optimizer.step() \n        \n        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        train_acc += (train_pred.detach() == labels.detach()).sum().item() # requires_grad as False\n        train_loss += loss.item()\n    \n    # validation\n    model.eval() # set the model to evaluation mode\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(val_loader)):\n            features, labels = batch\n            features = features.to(device) \n            labels = labels.to(device)\n            outputs = model(features)\n            \n            loss = criterion(outputs, labels) \n            \n            _, val_pred = torch.max(outputs, 1) \n            val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n            val_loss += loss.item()\n\n    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n    # if the model improves, save a checkpoint at this epoch\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), model_path)\n        print(f'saving model with acc {best_acc/len(val_set):.5f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:38:43.405391Z","iopub.execute_input":"2024-06-29T04:38:43.406378Z","iopub.status.idle":"2024-06-29T04:38:44.830032Z","shell.execute_reply.started":"2024-06-29T04:38:43.406324Z","shell.execute_reply":"2024-06-29T04:38:44.828693Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stderr","text":"  1%|          | 17/3103 [00:00<00:40, 75.63it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 52/3103 [00:00<00:22, 135.14it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 90/3103 [00:00<00:18, 162.04it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 127/3103 [00:00<00:17, 171.00it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 163/3103 [00:01<00:16, 175.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 193/3103 [00:01<00:19, 151.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\ntorch.Size([512, 117])\ntorch.Size([512, 41])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[168], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# set the model to training mode\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     16\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     17\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}