{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8814820,"sourceType":"datasetVersion","datasetId":5302416}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Target","metadata":{"id":"HpY_lOqEiEoi"}},{"cell_type":"markdown","source":"- Solve a classification problem with deep neural networks (DNNs)\n    - concat n frames\n    - add layers : Implement 2 models with approximately the same number of parameters, (A) one narrower and deeper (e.g. hidden_layers=6, hidden_dim=1024) and (B) the other wider and shallower (e.g. hidden_layers=2, hidden_dim=1750). Report training/validation accuracies for both models.\n    - batchnorm, dropout : Add dropout layers, and report training/validation accuracies with dropout rates equal to (A) 0.25/(B) 0.5/(C) 0.75 respectively.\n\n- Solve a classification problem with recursive neural networks (RNNs).\n\n\n","metadata":{"id":"UtmyTUQiiEoj"}},{"cell_type":"markdown","source":"# Library","metadata":{"id":"mTWqsisQiEoj"}},{"cell_type":"code","source":"import random\nimport os\nimport argparse\nfrom tqdm import tqdm\n\nimport numpy as np\n\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import DataLoader\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"G7Qog-4WiEok","execution":{"iopub.status.busy":"2024-07-01T13:52:04.113723Z","iopub.execute_input":"2024-07-01T13:52:04.114422Z","iopub.status.idle":"2024-07-01T13:52:07.863144Z","shell.execute_reply.started":"2024-07-01T13:52:04.114386Z","shell.execute_reply":"2024-07-01T13:52:07.862057Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Helper function","metadata":{"id":"M22yFwUeiEok"}},{"cell_type":"markdown","source":"- `random.seed(seed)`: Sets the seed for **Python's built-in** random module.\n- `np.random.seed(seed)`: Sets the seed for **NumPy's** random number generator.\n- `torch.manual_seed(seed)`: Sets the seed for **PyTorch on the CPU**.\n- `torch.cuda.manual_seed(seed)`: Sets the seed for the **current GPU**.\n- `torch.cuda.manual_seed_all(seed)`: Sets the seed for **all GPUs**.\n- `torch.backends.cudnn.benchmark = False`: Disables the CuDNN benchmark mode.\n- `torch.backends.cudnn.deterministic = True`: Forces CuDNN to use deterministic algorithms, which helps in reproducibility.","metadata":{"id":"OY55FqOHiEok"}},{"cell_type":"markdown","source":"`torch.backends.cudnn.benchmark` 是 PyTorch 的一個設置，用來啟用或禁用 CuDNN 的基準模式：\n\n- True：讓 CuDNN 尋找最佳的卷積算法，可能提高訓練速度，但結果可能不可重現。\n- False：使用固定的算法，確保結果可重現，通常用於測試和比較實驗結果。\n\n**在追求可重現性時，可設置為 False**","metadata":{"id":"tlxGHmJyiEol"}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmarkbe = False\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"xzXjb4_3iEol","execution":{"iopub.status.busy":"2024-07-01T13:52:07.864778Z","iopub.execute_input":"2024-07-01T13:52:07.865167Z","iopub.status.idle":"2024-07-01T13:52:07.870914Z","shell.execute_reply.started":"2024-07-01T13:52:07.865133Z","shell.execute_reply":"2024-07-01T13:52:07.869867Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"- 函數：\n\n`load_feat(path)`：\n\n    從指定路徑加載 PyTorch 張量。\n\n`shift(x, n)`：\n\n    將張量 x 向左或向右移動 n 個位置。\n    根據移動方向用第一或最後一個元素填充。\n\n`concat_feat(x, concat_n)`：\n\n    在每個幀周圍串聯 concat_n 幀。\n    確保 concat_n 是奇數。\n    使用 shift 函數來正確調整每個幀。\n\n- 主函數：\n`preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8)`：\n\n    用於訓練、驗證或測試的數據預處理。\n    加載和串聯特徵。\n    根據 train_ratio 將數據拆分為訓練集和驗證集。\n    \n    - 步驟：\n\n        - 加載數據：\n\n            讀取標籤並拆分數據集。\n            使用 load_feat 加載特徵文件。\n            特徵串聯：\n\n            使用 concat_feat 串聯幀以提供上下文。\n            數據準備：\n\n            為特徵 (X) 和標籤 (y) 準備張量。\n\n        - 輸出：\n\n            返回處理好的訓練/驗證集的特徵和標籤張量，或僅返回測試集的特徵。\n            關鍵點：\n            concat_nframes 必須是奇數以確保對稱上下文。\n            train_ratio 控制訓練和驗證之間的拆分比例。\n            預定義的最大長度 (max_len) 保證了內存的高效分配，可以根據需要調整。\n            使用 tqdm 來追踪進度。","metadata":{"id":"yHshvCRPiEol"}},{"cell_type":"markdown","source":"---","metadata":{"id":"g_SrlgDjiEom"}},{"cell_type":"code","source":"def load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x: torch.Tensor, n: int) -> torch.Tensor:\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x: torch.Tensor, concat_n: int):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n)\n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n","metadata":{"id":"lRvCD6SDiEom","execution":{"iopub.status.busy":"2024-07-01T13:52:07.982335Z","iopub.execute_input":"2024-07-01T13:52:07.983035Z","iopub.status.idle":"2024-07-01T13:52:07.995022Z","shell.execute_reply.started":"2024-07-01T13:52:07.983000Z","shell.execute_reply":"2024-07-01T13:52:07.993837Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{"id":"8VsqdSdDiEom"}},{"cell_type":"code","source":"test = torch.Tensor([[1,2,3],\n                     [4,5,6],\n                     [7,8,9],\n                     [10,11,12]])\n\nshift(test,2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.513179Z","iopub.execute_input":"2024-06-29T03:17:51.514108Z","iopub.status.idle":"2024-06-29T03:17:51.522560Z","shell.execute_reply.started":"2024-06-29T03:17:51.514070Z","shell.execute_reply":"2024-06-29T03:17:51.521541Z"},"id":"5QbgnFTaiEom","outputId":"6bc44efb-14ec-46da-b8ff-6e309be672c9","trusted":true},"execution_count":null,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"tensor([[ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.],\n        [10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.704742Z","iopub.execute_input":"2024-06-29T03:17:51.705665Z","iopub.status.idle":"2024-06-29T03:17:51.711800Z","shell.execute_reply.started":"2024-06-29T03:17:51.705630Z","shell.execute_reply":"2024-06-29T03:17:51.710743Z"},"id":"iatat8V4iEom","outputId":"6f4689a1-5782-4789-c482-92606d136dad","trusted":true},"execution_count":null,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 3])"},"metadata":{}}]},{"cell_type":"code","source":"test.repeat(1, 3).shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.907636Z","iopub.execute_input":"2024-06-29T03:17:51.908016Z","iopub.status.idle":"2024-06-29T03:17:51.914929Z","shell.execute_reply.started":"2024-06-29T03:17:51.907983Z","shell.execute_reply":"2024-06-29T03:17:51.913865Z"},"id":"vvT91vwBiEon","outputId":"6997baa0-19d7-4b2f-9320-8c20f11ffc82","trusted":true},"execution_count":null,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 9])"},"metadata":{}}]},{"cell_type":"code","source":"seq_len, feature_len = test.size(0), test.size(1) # 4*3\ntest = test.repeat(1, 3) # 4*9\ntest.view(seq_len, 3, feature_len) # 4 *3 *3","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:52.092907Z","iopub.execute_input":"2024-06-29T03:17:52.093945Z","iopub.status.idle":"2024-06-29T03:17:52.102385Z","shell.execute_reply.started":"2024-06-29T03:17:52.093906Z","shell.execute_reply":"2024-06-29T03:17:52.101360Z"},"id":"XNZ0qF3MiEon","outputId":"10dae984-e4fc-4eaf-ec59-09f4cf38c3c1","trusted":true},"execution_count":null,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 1.,  2.,  3.],\n         [ 1.,  2.,  3.]],\n\n        [[ 4.,  5.,  6.],\n         [ 4.,  5.,  6.],\n         [ 4.,  5.,  6.]],\n\n        [[ 7.,  8.,  9.],\n         [ 7.,  8.,  9.],\n         [ 7.,  8.,  9.]],\n\n        [[10., 11., 12.],\n         [10., 11., 12.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"test = test.view(seq_len, 3, feature_len).permute(1, 0, 2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:08.953858Z","iopub.execute_input":"2024-06-29T03:18:08.954523Z","iopub.status.idle":"2024-06-29T03:18:08.959533Z","shell.execute_reply.started":"2024-06-29T03:18:08.954484Z","shell.execute_reply":"2024-06-29T03:18:08.958413Z"},"id":"1OcRZVUOiEoo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test  # 3*4*3 permute() rearange tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:10.909438Z","iopub.execute_input":"2024-06-29T03:18:10.910539Z","iopub.status.idle":"2024-06-29T03:18:10.918809Z","shell.execute_reply.started":"2024-06-29T03:18:10.910493Z","shell.execute_reply":"2024-06-29T03:18:10.917673Z"},"id":"cYaUhiaZiEoo","outputId":"4cc7cc3a-bcd5-42be-f55b-ee79f97b5eec","trusted":true},"execution_count":null,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"mid = (3 // 2) # 1\nfor r_idx in range(1, mid+1): # 1\n    a = shift(test[mid + r_idx], r_idx)\n    test[mid + r_idx, :] = a\n    print(a)\n\n    b = shift(test[mid - r_idx], -r_idx)\n    test[mid - r_idx, :] = b\n    print(b)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:19:56.502913Z","iopub.execute_input":"2024-06-29T03:19:56.503370Z","iopub.status.idle":"2024-06-29T03:19:56.513391Z","shell.execute_reply.started":"2024-06-29T03:19:56.503335Z","shell.execute_reply":"2024-06-29T03:19:56.512321Z"},"id":"6kMdLADLiEoo","outputId":"ffbbb2cc-3661-41ed-e83f-66785d1374e5","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"tensor([[ 4.,  5.,  6.],\n        [ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.]])\ntensor([[1., 2., 3.],\n        [1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"test.permute(1, 0, 2).view(seq_len, 3 * feature_len) # 4*9","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:21:45.364255Z","iopub.execute_input":"2024-06-29T03:21:45.364660Z","iopub.status.idle":"2024-06-29T03:21:45.373197Z","shell.execute_reply.started":"2024-06-29T03:21:45.364628Z","shell.execute_reply":"2024-06-29T03:21:45.372216Z"},"id":"5PlCE9WLiEoo","outputId":"52f6415a-4e46-47ac-fa59-a2ed2d346e11","trusted":true},"execution_count":null,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.,  2.,  3.,  1.,  2.,  3.,  4.,  5.,  6.],\n        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n        [ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n        [ 7.,  8.,  9., 10., 11., 12., 10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{"id":"m4ZrTA1jiEoo"}},{"cell_type":"code","source":"def preprocess_data(split: str, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n\n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    max_len = 3000000\n    X = torch.empty(max_len, 39 * concat_nframes)\n    if mode == 'train':\n        y = torch.empty(max_len, dtype=torch.long)\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n            label = torch.LongTensor(label_dict[fname])\n\n        X[idx: idx + cur_len, :] = feat\n        if mode == 'train':\n            y[idx: idx + cur_len] = label\n\n        idx += cur_len\n\n    X = X[:idx, :]\n    if mode == 'train':\n        y = y[:idx]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode == 'train':\n        print(y.shape)\n        return X, y\n    else:\n        return X","metadata":{"id":"8REax6bOiEop","execution":{"iopub.status.busy":"2024-07-01T13:54:18.707955Z","iopub.execute_input":"2024-07-01T13:54:18.708968Z","iopub.status.idle":"2024-07-01T13:54:18.724087Z","shell.execute_reply.started":"2024-07-01T13:54:18.708928Z","shell.execute_reply":"2024-07-01T13:54:18.722917Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{"id":"eyGRyrv0iEop"}},{"cell_type":"code","source":"label_dict = {}\nfor line in open(\"/kaggle/input/libraphone/libriphone/train_labels.txt\").readlines():\n    print(len(line))\n    line = line.strip('\\n').split(' ')\n    print(len(line))\n    label_dict[line[0]] = [int(p) for p in line[1:]]\n    print(label_dict)\n    break\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:48:11.979126Z","iopub.execute_input":"2024-06-29T03:48:11.979554Z","iopub.status.idle":"2024-06-29T03:48:11.999084Z","shell.execute_reply.started":"2024-06-29T03:48:11.979520Z","shell.execute_reply":"2024-06-29T03:48:11.998155Z"},"id":"vbREVenGiEop","outputId":"f39daec5-8d8a-439b-88d1-3d70d5c91dfb","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"2121\n841\n{'4830-25898-0031': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 12, 12, 27, 27, 27, 38, 38, 38, 38, 38, 38, 38, 35, 35, 35, 35, 35, 25, 25, 25, 25, 25, 25, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 37, 37, 37, 37, 37, 30, 30, 30, 30, 30, 30, 30, 30, 27, 27, 27, 4, 4, 4, 4, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 37, 37, 37, 37, 37, 37, 14, 14, 14, 14, 14, 14, 14, 4, 4, 4, 4, 4, 4, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 8, 8, 8, 8, 8, 8, 8, 8, 8, 27, 27, 27, 27, 27, 27, 27, 23, 23, 23, 23, 23, 23, 23, 23, 23, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 37, 37, 37, 37, 37, 37, 37, 27, 27, 27, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 35, 35, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40, 30, 30, 30, 30, 30, 30, 30, 30, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 40, 40, 40, 40, 40, 40, 40, 40, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 39, 39, 39, 39, 39, 39, 39, 39, 5, 5, 5, 5, 5, 5, 5, 5, 5, 12, 12, 12, 12, 12, 12, 12, 12, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 26, 26, 26, 26, 26, 26, 26, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 27, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 2, 2, 2, 2, 2, 2, 2, 2, 16, 16, 16, 16, 16, 16, 16, 16, 31, 31, 31, 31, 31, 31, 31, 31, 23, 23, 23, 23, 9, 9, 9, 9, 9, 9, 9, 9, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"split = \"train\"\n\nusage_list = open(\"/kaggle/input/libraphone/libriphone/train_split.txt\").readlines()\nprint(f\"read first: {usage_list[0]}\")\nrandom.shuffle(usage_list)\nprint(f\"After shuffling: {usage_list[0]}\")\ntrain_len = int(len(usage_list) * 0.8)\nusage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\nprint(f\"After train split: {usage_list[0]}\")\nusage_list = [line.strip('\\n') for line in usage_list]\nprint(f\"Strip \\\\n: {usage_list[0]}\")\nprint('[Dataset] - # phone classes: ' + str(41) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:49:30.748076Z","iopub.execute_input":"2024-06-29T03:49:30.748484Z","iopub.status.idle":"2024-06-29T03:49:30.760407Z","shell.execute_reply.started":"2024-06-29T03:49:30.748433Z","shell.execute_reply":"2024-06-29T03:49:30.759330Z"},"id":"_EJLSY6TiEop","outputId":"a82258dd-21df-4147-e29d-1604f679f109","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"read first: 4830-25898-0031\n\nAfter shuffling: 2989-138028-0022\n\nAfter train split: 2989-138028-0022\n\nStrip \\n: 2989-138028-0022\n[Dataset] - # phone classes: 41, number of utterances for train: 2743\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----","metadata":{"id":"TVzLGLPhiEoq"}},{"cell_type":"markdown","source":"# Dataset\n","metadata":{"id":"sKw8INQWiEoq"}},{"cell_type":"code","source":"class LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"id":"ut9i51kUiEoq","execution":{"iopub.status.busy":"2024-07-01T13:52:40.641115Z","iopub.execute_input":"2024-07-01T13:52:40.641541Z","iopub.status.idle":"2024-07-01T13:52:40.649832Z","shell.execute_reply.started":"2024-07-01T13:52:40.641486Z","shell.execute_reply":"2024-07-01T13:52:40.648879Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"3G-ELUfLiEoq"}},{"cell_type":"markdown","source":"Base : Linear -> ReLU -> Linear ... + one narrower and deeper (hidden_layers=2, hidden_dim=64)\n\n1. Linear -> ReLU -> Linear ... + one narrower and deeper (hidden_layers=6, hidden_dim=1024)\n\n2.  Linear -> ReLU -> Linear ... + wider and shallower (hidden_layers=2, hidden_dim=1750)\n\n*use best perform in 1 or 2 to train follow model*\n\n3. Linear -> ReLU -> Dropout(.25_ -> Linear... : use base\n\n4. Linear -> ReLU -> Dropout(.5) -> Linear ... : use base\n\n5. Linear -> ReLU -> Dropout(.75) -> Linear ... : use base\n\n6. Linear -> ReLU -> Dropout(.75) -> Linear ... : use narrow and deeper\n\n*use best perform in 3, 4 or 5 to train follow model*\n\n6. Linear -> BN -> ReLU -> Dropout -> Linear ...\n\n7. Linear -> ReLU ->  Dropout -> BN -> Linear ...\n\n8. Concat 3, 5, 7, 9 frames\n\n9. RNN","metadata":{"id":"y8AUo9h3iEoq"}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self,\n                 input_dim,\n                 output_dim,\n                 eps=1e-05,\n                 momentum=0.1,\n                 drop_out_p = 0.5):\n\n        super().__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n            nn.Dropout(drop_out_p),\n            nn.BatchNorm1d(output_dim, eps=eps, momentum=momentum, affine=True),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self,\n                 input_dim,\n                 output_dim=41,\n                 hidden_layers=1,\n                 hidden_dim=256):\n\n        super().__init__()\n\n        self.fc = nn.Sequential(\n            BasicBlock(input_dim, hidden_dim),\n            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"id":"nQTNE4nfiEoq","execution":{"iopub.status.busy":"2024-07-01T13:52:49.987894Z","iopub.execute_input":"2024-07-01T13:52:49.988269Z","iopub.status.idle":"2024-07-01T13:52:49.998365Z","shell.execute_reply.started":"2024-07-01T13:52:49.988241Z","shell.execute_reply":"2024-07-01T13:52:49.997356Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{"id":"ieL05Sm5iEoq"}},{"cell_type":"code","source":"parser = argparse.ArgumentParser(description='設定資料與訓練參數')\n\n# 資料參數\nparser.add_argument('--concat_nframes', type=int, default=3,\n                    help='連接的幀數，n 必須為奇數 (總共 2k+1 = n 幀)')\nparser.add_argument('--train_ratio', type=float, default=0.75,\n                    help='訓練資料比例，其餘將用於驗證')\n\n# 訓練參數\nparser.add_argument('--seed', type=int, default=1213,\n                    help='隨機種子')\nparser.add_argument('--batch_size', type=int, default=512,\n                    help='批次大小')\nparser.add_argument('--num_epoch', type=int, default=10,\n                    help='訓練的 epoch 數量')\nparser.add_argument('--learning_rate', type=float, default=1e-4,\n                    help='學習率')\nparser.add_argument('--model_path', type=str, default='./model.ckpt',\n                    help='模型儲存的路徑')\n\n# 模型參數\nparser.add_argument('--input_dim', type=int, default=39 * 3,\n                    help='模型的輸入維度，不應更改此值')\nparser.add_argument('--hidden_layers', type=int, default=2,\n                    help='隱藏層的層數')\nparser.add_argument('--hidden_dim', type=int, default=64,\n                    help='隱藏層的維度')\n\nargs = parser.parse_args()\n\n# 打印參數設定\nprint('資料參數:')\nprint(f'- 連接的幀數: {args.concat_nframes}')\nprint(f'- 訓練資料比例: {args.train_ratio}')\n\nprint('\\n訓練參數:')\nprint(f'- 隨機種子: {args.seed}')\nprint(f'- 批次大小: {args.batch_size}')\nprint(f'- 訓練 epoch 數量: {args.num_epoch}')\nprint(f'- 學習率: {args.learning_rate}')\nprint(f'- 模型儲存路徑: {args.model_path}')\n\nprint('\\n模型參數:')\nprint(f'- 輸入維度: {args.input_dim}')\nprint(f'- 隱藏層數量: {args.hidden_layers}')\nprint(f'- 隱藏層維度: {args.hidden_dim}')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T03:54:41.215171Z","iopub.execute_input":"2024-06-30T03:54:41.215896Z","iopub.status.idle":"2024-06-30T03:54:41.230742Z","shell.execute_reply.started":"2024-06-30T03:54:41.215866Z","shell.execute_reply":"2024-06-30T03:54:41.229363Z"},"id":"-z-OoY9XiEoq","outputId":"708b9599-8590-4cc1-c8c4-6c77c69f9a75","trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"usage: ipykernel_launcher.py [-h] [--concat_nframes CONCAT_NFRAMES]\n                             [--train_ratio TRAIN_RATIO] [--seed SEED]\n                             [--batch_size BATCH_SIZE] [--num_epoch NUM_EPOCH]\n                             [--learning_rate LEARNING_RATE]\n                             [--model_path MODEL_PATH] [--input_dim INPUT_DIM]\n                             [--hidden_layers HIDDEN_LAYERS]\n                             [--hidden_dim HIDDEN_DIM]\nipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-ff0d29ad-f3d0-4a4e-b9bb-889736b77981.json\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"],"ename":"SystemExit","evalue":"2","output_type":"error"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 9              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 512                # batch size\nnum_epoch = 50                   # the number of training epoch\nlearning_rate = 1e-4         # learning rate\nmodel_path = './model_2.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 6              # the number of hidden layers\nhidden_dim = 1024             # the hidden dim","metadata":{"id":"79Nsdc9hiEoq","execution":{"iopub.status.busy":"2024-07-01T13:52:51.770552Z","iopub.execute_input":"2024-07-01T13:52:51.770973Z","iopub.status.idle":"2024-07-01T13:52:51.777049Z","shell.execute_reply.started":"2024-07-01T13:52:51.770925Z","shell.execute_reply":"2024-07-01T13:52:51.776002Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{"id":"6iAtZt3LiEoq"}},{"cell_type":"code","source":"same_seeds(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"id":"0-tWqXqliEoq","outputId":"8efc14e8-994b-43a4-baed-75884e8ed548","execution":{"iopub.status.busy":"2024-07-01T13:54:25.252324Z","iopub.execute_input":"2024-07-01T13:54:25.252758Z","iopub.status.idle":"2024-07-01T13:54:25.260312Z","shell.execute_reply.started":"2024-07-01T13:54:25.252726Z","shell.execute_reply":"2024-07-01T13:54:25.259300Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"DEVICE: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# preprocess data\ntrain_X, train_y = preprocess_data(split='train',\n                                   feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                                   phone_path='/kaggle/input/libraphone/libriphone',\n                                   concat_nframes=concat_nframes,\n                                   train_ratio=train_ratio)\n\nval_X, val_y = preprocess_data(split='val',\n                               feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                               phone_path='/kaggle/input/libraphone/libriphone',\n                               concat_nframes=concat_nframes,\n                               train_ratio=train_ratio)","metadata":{"id":"lBa3ub2iiEor","outputId":"452df553-07da-4f7c-c75d-ffb42ecf75f6","execution":{"iopub.status.busy":"2024-07-01T13:54:38.833971Z","iopub.execute_input":"2024-07-01T13:54:38.834634Z","iopub.status.idle":"2024-07-01T13:54:38.903236Z","shell.execute_reply.started":"2024-07-01T13:54:38.834599Z","shell.execute_reply":"2024-07-01T13:54:38.901899Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# preprocess data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_X, train_y \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mfeat_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/libraphone/libriphone/feat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mphone_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/libraphone/libriphone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mconcat_nframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_nframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_X, val_y \u001b[38;5;241m=\u001b[39m preprocess_data(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                feat_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/libraphone/libriphone/feat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                phone_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/libraphone/libriphone\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                concat_nframes\u001b[38;5;241m=\u001b[39mconcat_nframes,\n\u001b[1;32m     12\u001b[0m                                train_ratio\u001b[38;5;241m=\u001b[39mtrain_ratio)\n","Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(split, feat_dir, phone_path, concat_nframes, train_ratio)\u001b[0m\n\u001b[1;32m     11\u001b[0m label_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphone_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_labels.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[1;32m     14\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m         label_dict[line[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m line[\u001b[38;5;241m1\u001b[39m:]]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/libraphone/libriphone/train_labels.txt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/libraphone/libriphone/train_labels.txt'","output_type":"error"}]},{"cell_type":"code","source":"# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:51:14.728089Z","iopub.execute_input":"2024-06-30T13:51:14.728538Z","iopub.status.idle":"2024-06-30T13:51:14.732937Z","shell.execute_reply.started":"2024-06-30T13:51:14.728503Z","shell.execute_reply":"2024-06-30T13:51:14.732059Z"},"id":"IpXuVwhviEor","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:51:14.734210Z","iopub.execute_input":"2024-06-30T13:51:14.734655Z","iopub.status.idle":"2024-06-30T13:51:14.921192Z","shell.execute_reply.started":"2024-06-30T13:51:14.734622Z","shell.execute_reply":"2024-06-30T13:51:14.920268Z"},"id":"UoBt0eXPiEor","outputId":"c882c119-5c8d-4abe-9b24-008c6a35731a","trusted":true},"execution_count":null,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"396"},"metadata":{}}]},{"cell_type":"code","source":"# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:51:14.923708Z","iopub.execute_input":"2024-06-30T13:51:14.924703Z","iopub.status.idle":"2024-06-30T13:51:15.065259Z","shell.execute_reply.started":"2024-06-30T13:51:14.924665Z","shell.execute_reply":"2024-06-30T13:51:15.064330Z"},"id":"ckZN5Nu0iEor","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"-dZmD4ZHiEor"}},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:31:53.765681Z","iopub.execute_input":"2024-06-29T04:31:53.766306Z","iopub.status.idle":"2024-06-29T04:31:53.931501Z","shell.execute_reply.started":"2024-06-29T04:31:53.766273Z","shell.execute_reply":"2024-06-29T04:31:53.930309Z"},"id":"sxHS8GhKiEor","outputId":"2df2d2f8-5513-4343-9146-e0338f28b8d3","trusted":true},"execution_count":null,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"torch.Size([512, 117])"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(train_loader))[1].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:31:50.496380Z","iopub.execute_input":"2024-06-29T04:31:50.497052Z","iopub.status.idle":"2024-06-29T04:31:50.666419Z","shell.execute_reply.started":"2024-06-29T04:31:50.497016Z","shell.execute_reply":"2024-06-29T04:31:50.665225Z"},"id":"YP5rQe5XiEor","outputId":"15ca8efb-c11a-4829-a628-ec3a8db71e39","trusted":true},"execution_count":null,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"torch.Size([512])"},"metadata":{}}]},{"cell_type":"code","source":"# create model, define a loss function, and optimizer\nmodel = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:51:15.066385Z","iopub.execute_input":"2024-06-30T13:51:15.066723Z","iopub.status.idle":"2024-06-30T13:51:15.147316Z","shell.execute_reply.started":"2024-06-30T13:51:15.066700Z","shell.execute_reply":"2024-06-30T13:51:15.146636Z"},"id":"qKUmwK-ziEor","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_loader.dataset), len(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T15:18:08.336036Z","iopub.execute_input":"2024-06-29T15:18:08.336632Z","iopub.status.idle":"2024-06-29T15:18:08.343174Z","shell.execute_reply.started":"2024-06-29T15:18:08.336581Z","shell.execute_reply":"2024-06-29T15:18:08.342093Z"},"id":"wP4wDIpLiEor","outputId":"d81cbebc-59b3-467b-8e55-b09826eec416","trusted":true},"execution_count":null,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(1588590, 3103)"},"metadata":{}}]},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          data_loader: torch.utils.data.DataLoader,\n          loss_fn: torch.nn.Module,\n          optimizer: torch.optim.Optimizer,\n          device: torch.device):\n    model.train()\n    train_acc = 0.0\n    train_loss = 0.0\n    for features, labels in tqdm(data_loader):\n        features, labels = features.to(device), labels.to(device)\n        # 1. Froward pass\n        outputs = model(features)\n\n         # 2. Calculate loss\n        loss = loss_fn(outputs, labels)\n\n        # 3. Optimizer zer grade\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. optimizer step\n        optimizer.step()\n\n        _, train_pred = torch.max(outputs, 1)\n        train_acc += (train_pred == labels).sum().item()\n        train_loss += loss.item()\n\n    return train_acc / len(data_loader.dataset), train_loss / len(data_loader) #data_loader.dataset total sample size and data_loader batch size\n\ndef validate(model: torch.nn.Module,\n             data_loader: torch.utils.data.DataLoader,\n             loss_fn: torch.nn.Module,\n             device: torch.device):\n    model.eval()\n    val_acc = 0.0\n    val_loss = 0.0\n    with torch.no_grad():\n        for features, labels in tqdm(data_loader):\n            features, labels = features.to(device), labels.to(device)\n\n            outputs = model(features)\n            loss = loss_fn(outputs, labels)\n\n            _, val_pred = torch.max(outputs, 1)\n            val_acc += (val_pred == labels).sum().item()\n            val_loss += loss.item()\n\n    return val_acc / len(data_loader.dataset), val_loss / len(data_loader)\n\n\n# Main training loop\nbest_acc = 0.0\ntrain_info = {\n    \"Acc\":[],\n    \"Loss\":[]\n}\nval_info = {\n    \"Acc\":[],\n    \"Loss\":[]\n}\nfor epoch in range(num_epoch):\n    train_acc, train_loss = train(model, train_loader, criterion, optimizer, device)\n    val_acc, val_loss = validate(model, val_loader, criterion, device)\n    train_info[\"Acc\"].append(train_acc)\n    train_info[\"Loss\"].append(train_loss)\n    val_info[\"Acc\"].append(val_acc)\n    val_info[\"Loss\"].append(val_loss)\n    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc:.5f} Loss: {train_loss:.5f} | Val Acc: {val_acc:.5f} Loss: {val_loss:.5f}')\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), model_path)\n        print(f'Saving model with acc {best_acc:.5f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-30T13:51:15.148635Z","iopub.execute_input":"2024-06-30T13:51:15.148907Z"},"id":"SB3CSK3fiEos","outputId":"601a4834-46f7-4aa7-f793-ea4aee0d971a","trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 81.85it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[001/050] Train Acc: 0.41279 Loss: 2.06844 | Val Acc: 0.52572 Loss: 1.58022\nSaving model with acc 0.52572\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 81.20it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 149.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"[002/050] Train Acc: 0.50437 Loss: 1.66260 | Val Acc: 0.57158 Loss: 1.40289\nSaving model with acc 0.57158\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 81.12it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 147.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"[003/050] Train Acc: 0.53435 Loss: 1.54737 | Val Acc: 0.59293 Loss: 1.32110\nSaving model with acc 0.59293\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.91it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"[004/050] Train Acc: 0.55349 Loss: 1.47971 | Val Acc: 0.60922 Loss: 1.26355\nSaving model with acc 0.60922\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.52it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 147.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[005/050] Train Acc: 0.56616 Loss: 1.43330 | Val Acc: 0.62124 Loss: 1.21873\nSaving model with acc 0.62124\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.42it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 153.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"[006/050] Train Acc: 0.57550 Loss: 1.39953 | Val Acc: 0.62851 Loss: 1.19428\nSaving model with acc 0.62851\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.32it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"[007/050] Train Acc: 0.58333 Loss: 1.37270 | Val Acc: 0.63639 Loss: 1.16480\nSaving model with acc 0.63639\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.88it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 143.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"[008/050] Train Acc: 0.58895 Loss: 1.35146 | Val Acc: 0.64180 Loss: 1.14657\nSaving model with acc 0.64180\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:39<00:00, 77.98it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[009/050] Train Acc: 0.59400 Loss: 1.33253 | Val Acc: 0.64650 Loss: 1.12921\nSaving model with acc 0.64650\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.64it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 149.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[010/050] Train Acc: 0.59787 Loss: 1.31867 | Val Acc: 0.65009 Loss: 1.11408\nSaving model with acc 0.65009\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.84it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 147.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"[011/050] Train Acc: 0.60193 Loss: 1.30469 | Val Acc: 0.65394 Loss: 1.10197\nSaving model with acc 0.65394\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.32it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 149.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"[012/050] Train Acc: 0.60503 Loss: 1.29369 | Val Acc: 0.65737 Loss: 1.08908\nSaving model with acc 0.65737\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.45it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 150.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"[013/050] Train Acc: 0.60741 Loss: 1.28238 | Val Acc: 0.65948 Loss: 1.07952\nSaving model with acc 0.65948\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.36it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 147.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"[014/050] Train Acc: 0.60970 Loss: 1.27462 | Val Acc: 0.66182 Loss: 1.07228\nSaving model with acc 0.66182\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.55it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 146.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[015/050] Train Acc: 0.61195 Loss: 1.26506 | Val Acc: 0.66366 Loss: 1.06279\nSaving model with acc 0.66366\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.22it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 147.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"[016/050] Train Acc: 0.61476 Loss: 1.25746 | Val Acc: 0.66749 Loss: 1.05359\nSaving model with acc 0.66749\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.67it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"[017/050] Train Acc: 0.61663 Loss: 1.24984 | Val Acc: 0.66785 Loss: 1.04898\nSaving model with acc 0.66785\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.45it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 149.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[018/050] Train Acc: 0.61796 Loss: 1.24443 | Val Acc: 0.67082 Loss: 1.04028\nSaving model with acc 0.67082\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.27it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"[019/050] Train Acc: 0.61932 Loss: 1.23902 | Val Acc: 0.67277 Loss: 1.03387\nSaving model with acc 0.67277\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.41it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 144.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"[020/050] Train Acc: 0.62117 Loss: 1.23260 | Val Acc: 0.67424 Loss: 1.03042\nSaving model with acc 0.67424\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.27it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 146.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"[021/050] Train Acc: 0.62273 Loss: 1.22692 | Val Acc: 0.67551 Loss: 1.02340\nSaving model with acc 0.67551\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.65it/s]\n100%|██████████| 1037/1037 [00:07<00:00, 146.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[022/050] Train Acc: 0.62414 Loss: 1.22187 | Val Acc: 0.67713 Loss: 1.01769\nSaving model with acc 0.67713\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 80.28it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"[023/050] Train Acc: 0.62524 Loss: 1.21835 | Val Acc: 0.67830 Loss: 1.01283\nSaving model with acc 0.67830\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3113/3113 [00:38<00:00, 81.14it/s]\n100%|██████████| 1037/1037 [00:06<00:00, 148.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"[024/050] Train Acc: 0.62637 Loss: 1.21407 | Val Acc: 0.67940 Loss: 1.00987\nSaving model with acc 0.67940\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 938/3113 [00:11<00:26, 83.39it/s]","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Plotting the results with Seaborn\nepochs = range(1, num_epoch + 1)\n\nsns.set(style='whitegrid')\n\nplt.figure(figsize=(12, 5))\n\n# Plot accuracy\nplt.subplot(1, 2, 1)\nsns.lineplot(x=epochs, y=train_info[\"Acc\"], label='Training Accuracy')\nsns.lineplot(x=epochs, y=val_info[\"Acc\"], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nsns.lineplot(x=epochs, y=train_info[\"Loss\"], label='Training Loss')\nsns.lineplot(x=epochs, y=val_info[\"Loss\"], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"Model_2.png\")\nplt.show()","metadata":{"id":"WbR2iOn8iEos","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare Result with different Model","metadata":{"id":"OyER49VRiEos"}},{"cell_type":"markdown","source":"**Base**\n\n![image.png](attachment:4373f474-b07f-440e-a058-994c20029480.png)","metadata":{"id":"gWKkJqUxiEos"}},{"cell_type":"markdown","source":"**Narrow and Depper**\n\n![image.png](attachment:435d6720-2070-4b29-b475-b3e0ed267965.png)\n\n*Notes*\n- Starting over fitting after 7tg or 8th epochs.","metadata":{"id":"O93enyuLiEos"}},{"cell_type":"markdown","source":"**wider and shallower**\n\nTypical disadvantage of wide and shallow model:\n- Computational Complexity:\n    >A wide and shallow network with a vast number of input neurons can result in high computational complexity. Training and making predictions with such networks may be computationally expensive, especially as the number of **parameters increases**.\n- Overfitting:\n    >Shallow networks may struggle with capturing complex patterns in the data. The model might end up fitting the training data too closely, leading to overfitting. Overfitting occurs when the model performs well on training data but poorly on unseen data.\n- Limited Representational Power:\n    >Shallow networks might not have enough depth to learn hierarchical representations of features in the data. Deep networks, with multiple hidden layers, are often better suited for **capturing intricate relationships and representations**.\n- Feature Extraction Challenges:\n    >Wide and shallow networks may face challenges in automatic feature extraction. Deep networks, by design, learn hierarchical features from data, allowing them to automatically **extract and represent meaningful features**.\n\n\n![image.png](attachment:9ae31e8c-b189-43ba-a3d7-5975f33760c5.png)\n\n*Notes*\n\n- Here, we only see the time of training is longer than deeper model, which we train last.","metadata":{"id":"gDbo0dD2iEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.25**\n\n![image.png](attachment:90438905-0288-4be4-ae0b-867881d5fe62.png)\n\n*Notes*\n\n- Because the train set and validation set are not that overlap when we trained, it seems not that easy to overfitting.","metadata":{"id":"jLbuE2gciEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.5**\n\n![image.png](attachment:7255f60f-393c-4198-b659-0ee5f049a34e.png)\n\n*Notes*\n\n- As we increse the rate, we see it more flater after 20 epochs than 0.25 rate","metadata":{"id":"Z0OYnisZiEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.75**\n\n![image.png](attachment:30e85442-34c5-4aa9-b00f-fba859cf4dfc.png)\n\n*Notes*\n\n- A big problem is we increse the rate to prevent over fitting, but it will under fitting.\n\n*Insights*\n\n- We can use deeper and narrow model and deop out to train model.","metadata":{"id":"Uqzds3R8iEos"}},{"cell_type":"markdown","source":"**drop out rate 0.5 and deep + narrow model**\n\n![image.png](attachment:c4387e4f-4531-4d98-aae8-9de0a9372758.png)\n\n*Notes*\n\n- It doesn't overfitting and the accuracy is the highest so far.","metadata":{"id":"_Wrt7OqAiEot"}},{"cell_type":"markdown","source":"**BN -> ReLU -> Dropout**\n\n![image.png](attachment:23920f65-b5b6-4744-9f59-4d0cc2933674.png)","metadata":{"id":"5oT1CAvbiEot"}},{"cell_type":"markdown","source":"**Linear -> ReLU -> Dropout -> BN -> Linear**\n\n![image.png](attachment:6cfd7444-53aa-4525-ad26-6d4995591b4e.png)","metadata":{"id":"B79KaRfOiEot"}},{"cell_type":"markdown","source":"**Concat 5**\n\n![image.png](attachment:3694e598-a193-41f6-ba8a-fd94f7cbe236.png)","metadata":{"id":"DMhV_IN9iEot"}},{"cell_type":"markdown","source":"**Concat 7**\n\n![image.png](attachment:2801749b-0b7d-4761-91e9-ad3883eac6ba.png)","metadata":{"id":"rIMMj5XeiEot"}},{"cell_type":"code","source":"","metadata":{"id":"Za_gF1UziEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_-eDHEVmiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"D4ptYamsiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"HawFQRBNiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"oLFegT1hiEot"},"execution_count":null,"outputs":[]}]}