{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8814820,"sourceType":"datasetVersion","datasetId":5302416},{"sourceType":"kernelVersion","sourceId":186007146}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Target","metadata":{"id":"HpY_lOqEiEoi"}},{"cell_type":"markdown","source":"- Solve a classification problem with deep neural networks (DNNs)\n    - concat n frames\n    - add layers : Implement 2 models with approximately the same number of parameters, (A) one narrower and deeper (e.g. hidden_layers=6, hidden_dim=1024) and (B) the other wider and shallower (e.g. hidden_layers=2, hidden_dim=1750). Report training/validation accuracies for both models.\n    - batchnorm, dropout : Add dropout layers, and report training/validation accuracies with dropout rates equal to (A) 0.25/(B) 0.5/(C) 0.75 respectively.\n\n- Solve a classification problem with recursive neural networks (RNNs).\n\n\n","metadata":{"id":"UtmyTUQiiEoj"}},{"cell_type":"markdown","source":"# Library","metadata":{"id":"mTWqsisQiEoj"}},{"cell_type":"code","source":"import random\nimport os\nimport argparse\nfrom tqdm import tqdm\n\nimport numpy as np\n\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nimport torch\nfrom torch.utils.data import DataLoader\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"G7Qog-4WiEok","execution":{"iopub.status.busy":"2024-07-01T13:56:55.719105Z","iopub.execute_input":"2024-07-01T13:56:55.719505Z","iopub.status.idle":"2024-07-01T13:56:58.978428Z","shell.execute_reply.started":"2024-07-01T13:56:55.719476Z","shell.execute_reply":"2024-07-01T13:56:58.977478Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Helper function","metadata":{"id":"M22yFwUeiEok"}},{"cell_type":"markdown","source":"- `random.seed(seed)`: Sets the seed for **Python's built-in** random module.\n- `np.random.seed(seed)`: Sets the seed for **NumPy's** random number generator.\n- `torch.manual_seed(seed)`: Sets the seed for **PyTorch on the CPU**.\n- `torch.cuda.manual_seed(seed)`: Sets the seed for the **current GPU**.\n- `torch.cuda.manual_seed_all(seed)`: Sets the seed for **all GPUs**.\n- `torch.backends.cudnn.benchmark = False`: Disables the CuDNN benchmark mode.\n- `torch.backends.cudnn.deterministic = True`: Forces CuDNN to use deterministic algorithms, which helps in reproducibility.","metadata":{"id":"OY55FqOHiEok"}},{"cell_type":"markdown","source":"`torch.backends.cudnn.benchmark` 是 PyTorch 的一個設置，用來啟用或禁用 CuDNN 的基準模式：\n\n- True：讓 CuDNN 尋找最佳的卷積算法，可能提高訓練速度，但結果可能不可重現。\n- False：使用固定的算法，確保結果可重現，通常用於測試和比較實驗結果。\n\n**在追求可重現性時，可設置為 False**","metadata":{"id":"tlxGHmJyiEol"}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmarkbe = False\n    torch.backends.cudnn.deterministic = True","metadata":{"id":"xzXjb4_3iEol","execution":{"iopub.status.busy":"2024-07-01T13:56:58.980423Z","iopub.execute_input":"2024-07-01T13:56:58.980963Z","iopub.status.idle":"2024-07-01T13:56:58.988986Z","shell.execute_reply.started":"2024-07-01T13:56:58.980926Z","shell.execute_reply":"2024-07-01T13:56:58.987831Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"- 函數：\n\n`load_feat(path)`：\n\n    從指定路徑加載 PyTorch 張量。\n\n`shift(x, n)`：\n\n    將張量 x 向左或向右移動 n 個位置。\n    根據移動方向用第一或最後一個元素填充。\n\n`concat_feat(x, concat_n)`：\n\n    在每個幀周圍串聯 concat_n 幀。\n    確保 concat_n 是奇數。\n    使用 shift 函數來正確調整每個幀。\n\n- 主函數：\n`preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8)`：\n\n    用於訓練、驗證或測試的數據預處理。\n    加載和串聯特徵。\n    根據 train_ratio 將數據拆分為訓練集和驗證集。\n    \n    - 步驟：\n\n        - 加載數據：\n\n            讀取標籤並拆分數據集。\n            使用 load_feat 加載特徵文件。\n            特徵串聯：\n\n            使用 concat_feat 串聯幀以提供上下文。\n            數據準備：\n\n            為特徵 (X) 和標籤 (y) 準備張量。\n\n        - 輸出：\n\n            返回處理好的訓練/驗證集的特徵和標籤張量，或僅返回測試集的特徵。\n            關鍵點：\n            concat_nframes 必須是奇數以確保對稱上下文。\n            train_ratio 控制訓練和驗證之間的拆分比例。\n            預定義的最大長度 (max_len) 保證了內存的高效分配，可以根據需要調整。\n            使用 tqdm 來追踪進度。","metadata":{"id":"yHshvCRPiEol"}},{"cell_type":"markdown","source":"---","metadata":{"id":"g_SrlgDjiEom"}},{"cell_type":"code","source":"def load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x: torch.Tensor, n: int) -> torch.Tensor:\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x: torch.Tensor, concat_n: int):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n)\n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n","metadata":{"id":"lRvCD6SDiEom","execution":{"iopub.status.busy":"2024-07-01T13:56:58.990123Z","iopub.execute_input":"2024-07-01T13:56:58.990474Z","iopub.status.idle":"2024-07-01T13:56:59.001578Z","shell.execute_reply.started":"2024-07-01T13:56:58.990443Z","shell.execute_reply":"2024-07-01T13:56:59.000706Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{"id":"8VsqdSdDiEom"}},{"cell_type":"code","source":"test = torch.Tensor([[1,2,3],\n                     [4,5,6],\n                     [7,8,9],\n                     [10,11,12]])\n\nshift(test,2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.513179Z","iopub.execute_input":"2024-06-29T03:17:51.514108Z","iopub.status.idle":"2024-06-29T03:17:51.522560Z","shell.execute_reply.started":"2024-06-29T03:17:51.514070Z","shell.execute_reply":"2024-06-29T03:17:51.521541Z"},"id":"5QbgnFTaiEom","outputId":"6bc44efb-14ec-46da-b8ff-6e309be672c9","trusted":true},"execution_count":null,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"tensor([[ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.],\n        [10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.704742Z","iopub.execute_input":"2024-06-29T03:17:51.705665Z","iopub.status.idle":"2024-06-29T03:17:51.711800Z","shell.execute_reply.started":"2024-06-29T03:17:51.705630Z","shell.execute_reply":"2024-06-29T03:17:51.710743Z"},"id":"iatat8V4iEom","outputId":"6f4689a1-5782-4789-c482-92606d136dad","trusted":true},"execution_count":null,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 3])"},"metadata":{}}]},{"cell_type":"code","source":"test.repeat(1, 3).shape","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:51.907636Z","iopub.execute_input":"2024-06-29T03:17:51.908016Z","iopub.status.idle":"2024-06-29T03:17:51.914929Z","shell.execute_reply.started":"2024-06-29T03:17:51.907983Z","shell.execute_reply":"2024-06-29T03:17:51.913865Z"},"id":"vvT91vwBiEon","outputId":"6997baa0-19d7-4b2f-9320-8c20f11ffc82","trusted":true},"execution_count":null,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 9])"},"metadata":{}}]},{"cell_type":"code","source":"seq_len, feature_len = test.size(0), test.size(1) # 4*3\ntest = test.repeat(1, 3) # 4*9\ntest.view(seq_len, 3, feature_len) # 4 *3 *3","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:52.092907Z","iopub.execute_input":"2024-06-29T03:17:52.093945Z","iopub.status.idle":"2024-06-29T03:17:52.102385Z","shell.execute_reply.started":"2024-06-29T03:17:52.093906Z","shell.execute_reply":"2024-06-29T03:17:52.101360Z"},"id":"XNZ0qF3MiEon","outputId":"10dae984-e4fc-4eaf-ec59-09f4cf38c3c1","trusted":true},"execution_count":null,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 1.,  2.,  3.],\n         [ 1.,  2.,  3.]],\n\n        [[ 4.,  5.,  6.],\n         [ 4.,  5.,  6.],\n         [ 4.,  5.,  6.]],\n\n        [[ 7.,  8.,  9.],\n         [ 7.,  8.,  9.],\n         [ 7.,  8.,  9.]],\n\n        [[10., 11., 12.],\n         [10., 11., 12.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"test = test.view(seq_len, 3, feature_len).permute(1, 0, 2)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:08.953858Z","iopub.execute_input":"2024-06-29T03:18:08.954523Z","iopub.status.idle":"2024-06-29T03:18:08.959533Z","shell.execute_reply.started":"2024-06-29T03:18:08.954484Z","shell.execute_reply":"2024-06-29T03:18:08.958413Z"},"id":"1OcRZVUOiEoo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test  # 3*4*3 permute() rearange tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:18:10.909438Z","iopub.execute_input":"2024-06-29T03:18:10.910539Z","iopub.status.idle":"2024-06-29T03:18:10.918809Z","shell.execute_reply.started":"2024-06-29T03:18:10.910493Z","shell.execute_reply":"2024-06-29T03:18:10.917673Z"},"id":"cYaUhiaZiEoo","outputId":"4cc7cc3a-bcd5-42be-f55b-ee79f97b5eec","trusted":true},"execution_count":null,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]]])"},"metadata":{}}]},{"cell_type":"code","source":"mid = (3 // 2) # 1\nfor r_idx in range(1, mid+1): # 1\n    a = shift(test[mid + r_idx], r_idx)\n    test[mid + r_idx, :] = a\n    print(a)\n\n    b = shift(test[mid - r_idx], -r_idx)\n    test[mid - r_idx, :] = b\n    print(b)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:19:56.502913Z","iopub.execute_input":"2024-06-29T03:19:56.503370Z","iopub.status.idle":"2024-06-29T03:19:56.513391Z","shell.execute_reply.started":"2024-06-29T03:19:56.503335Z","shell.execute_reply":"2024-06-29T03:19:56.512321Z"},"id":"6kMdLADLiEoo","outputId":"ffbbb2cc-3661-41ed-e83f-66785d1374e5","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"tensor([[ 4.,  5.,  6.],\n        [ 7.,  8.,  9.],\n        [10., 11., 12.],\n        [10., 11., 12.]])\ntensor([[1., 2., 3.],\n        [1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n","output_type":"stream"}]},{"cell_type":"code","source":"test.permute(1, 0, 2).view(seq_len, 3 * feature_len) # 4*9","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:21:45.364255Z","iopub.execute_input":"2024-06-29T03:21:45.364660Z","iopub.status.idle":"2024-06-29T03:21:45.373197Z","shell.execute_reply.started":"2024-06-29T03:21:45.364628Z","shell.execute_reply":"2024-06-29T03:21:45.372216Z"},"id":"5PlCE9WLiEoo","outputId":"52f6415a-4e46-47ac-fa59-a2ed2d346e11","trusted":true},"execution_count":null,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.,  2.,  3.,  1.,  2.,  3.,  4.,  5.,  6.],\n        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n        [ 4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.],\n        [ 7.,  8.,  9., 10., 11., 12., 10., 11., 12.]])"},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{"id":"m4ZrTA1jiEoo"}},{"cell_type":"code","source":"def preprocess_data(split: str, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n\n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    max_len = 30000\n    number_of_data = 4000\n    X = torch.empty(number_of_data, max_len, 39 * concat_nframes)\n    if mode == 'train':\n        y = torch.empty(number_of_data, max_len, dtype=torch.long)\n    \n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt')) # nframes * dims\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes) # nframes * dims*concat_n\n        if mode == 'train':\n            label = torch.LongTensor(label_dict[fname]) #nframes\n        X[idx, :cur_len, :] = feat\n        if mode == 'train':\n            y[idx, :cur_len] = label\n\n        idx += 1\n\n    X = X[:idx,: , :]\n    if mode == 'train':\n        y = y[:idx, :]\n\n    print(f'[INFO] {split} set')\n    print(X.shape)\n    if mode == 'train':\n        print(y.shape)\n        return X, y\n    else:\n        return X","metadata":{"id":"8REax6bOiEop","execution":{"iopub.status.busy":"2024-07-01T14:46:30.050867Z","iopub.execute_input":"2024-07-01T14:46:30.051570Z","iopub.status.idle":"2024-07-01T14:46:30.065444Z","shell.execute_reply.started":"2024-07-01T14:46:30.051532Z","shell.execute_reply":"2024-07-01T14:46:30.064519Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"**Explain**","metadata":{"id":"eyGRyrv0iEop"}},{"cell_type":"code","source":"label_dict = {}\nfor line in open(\"/kaggle/input/libraphone/libriphone/train_labels.txt\").readlines():\n    print(len(line))\n    line = line.strip('\\n').split(' ')\n    print(len(line))\n    label_dict[line[0]] = [int(p) for p in line[1:]]\n    print(label_dict)\n    break\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:48:11.979126Z","iopub.execute_input":"2024-06-29T03:48:11.979554Z","iopub.status.idle":"2024-06-29T03:48:11.999084Z","shell.execute_reply.started":"2024-06-29T03:48:11.979520Z","shell.execute_reply":"2024-06-29T03:48:11.998155Z"},"id":"vbREVenGiEop","outputId":"f39daec5-8d8a-439b-88d1-3d70d5c91dfb","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"2121\n841\n{'4830-25898-0031': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 12, 12, 27, 27, 27, 38, 38, 38, 38, 38, 38, 38, 35, 35, 35, 35, 35, 25, 25, 25, 25, 25, 25, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 37, 37, 37, 37, 37, 30, 30, 30, 30, 30, 30, 30, 30, 27, 27, 27, 4, 4, 4, 4, 31, 31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 37, 37, 37, 37, 37, 37, 14, 14, 14, 14, 14, 14, 14, 4, 4, 4, 4, 4, 4, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 8, 8, 8, 8, 8, 8, 8, 8, 8, 27, 27, 27, 27, 27, 27, 27, 23, 23, 23, 23, 23, 23, 23, 23, 23, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 30, 9, 9, 9, 9, 9, 9, 37, 37, 37, 37, 37, 37, 37, 27, 27, 27, 27, 27, 27, 13, 13, 13, 13, 13, 13, 13, 13, 35, 35, 35, 35, 35, 35, 35, 40, 40, 40, 40, 40, 30, 30, 30, 30, 30, 30, 30, 30, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 40, 40, 40, 40, 40, 40, 40, 40, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 39, 39, 39, 39, 39, 39, 39, 39, 5, 5, 5, 5, 5, 5, 5, 5, 5, 12, 12, 12, 12, 12, 12, 12, 12, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 26, 26, 26, 26, 26, 26, 26, 4, 4, 4, 4, 4, 4, 27, 27, 27, 27, 27, 27, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 28, 28, 28, 28, 28, 28, 28, 28, 28, 27, 27, 27, 27, 27, 27, 27, 2, 2, 2, 2, 2, 2, 2, 2, 16, 16, 16, 16, 16, 16, 16, 16, 31, 31, 31, 31, 31, 31, 31, 31, 23, 23, 23, 23, 9, 9, 9, 9, 9, 9, 9, 9, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"split = \"train\"\n\nusage_list = open(\"/kaggle/input/libraphone/libriphone/train_split.txt\").readlines()\nprint(f\"read first: {usage_list[0]}\")\nrandom.shuffle(usage_list)\nprint(f\"After shuffling: {usage_list[0]}\")\ntrain_len = int(len(usage_list) * 0.8)\nusage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\nprint(f\"After train split: {usage_list[0]}\")\nusage_list = [line.strip('\\n') for line in usage_list]\nprint(f\"Strip \\\\n: {usage_list[0]}\")\nprint('[Dataset] - # phone classes: ' + str(41) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:49:30.748076Z","iopub.execute_input":"2024-06-29T03:49:30.748484Z","iopub.status.idle":"2024-06-29T03:49:30.760407Z","shell.execute_reply.started":"2024-06-29T03:49:30.748433Z","shell.execute_reply":"2024-06-29T03:49:30.759330Z"},"id":"_EJLSY6TiEop","outputId":"a82258dd-21df-4147-e29d-1604f679f109","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"read first: 4830-25898-0031\n\nAfter shuffling: 2989-138028-0022\n\nAfter train split: 2989-138028-0022\n\nStrip \\n: 2989-138028-0022\n[Dataset] - # phone classes: 41, number of utterances for train: 2743\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----","metadata":{"id":"TVzLGLPhiEoq"}},{"cell_type":"markdown","source":"# Dataset\n","metadata":{"id":"sKw8INQWiEoq"}},{"cell_type":"code","source":"class LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"id":"ut9i51kUiEoq","execution":{"iopub.status.busy":"2024-07-01T13:57:05.480108Z","iopub.execute_input":"2024-07-01T13:57:05.480459Z","iopub.status.idle":"2024-07-01T13:57:05.486905Z","shell.execute_reply.started":"2024-07-01T13:57:05.480430Z","shell.execute_reply":"2024-07-01T13:57:05.485988Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"3G-ELUfLiEoq"}},{"cell_type":"markdown","source":"Base : Linear -> ReLU -> Linear ... + one narrower and deeper (hidden_layers=2, hidden_dim=64)\n\n1. Linear -> ReLU -> Linear ... + one narrower and deeper (hidden_layers=6, hidden_dim=1024)\n\n2.  Linear -> ReLU -> Linear ... + wider and shallower (hidden_layers=2, hidden_dim=1750)\n\n*use best perform in 1 or 2 to train follow model*\n\n3. Linear -> ReLU -> Dropout(.25_ -> Linear... : use base\n\n4. Linear -> ReLU -> Dropout(.5) -> Linear ... : use base\n\n5. Linear -> ReLU -> Dropout(.75) -> Linear ... : use base\n\n6. Linear -> ReLU -> Dropout(.75) -> Linear ... : use narrow and deeper\n\n*use best perform in 3, 4 or 5 to train follow model*\n\n6. Linear -> BN -> ReLU -> Dropout -> Linear ...\n\n7. Linear -> ReLU ->  Dropout -> BN -> Linear ...\n\n8. Concat 3, 5, 7, 9 frames\n\n9. RNN","metadata":{"id":"y8AUo9h3iEoq"}},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self,\n                 input_dim,\n                 hidden_dim,\n                 output_dim=41):\n\n        super().__init__()\n\n        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=2, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        _, hidden = self.rnn(x)\n        out = hidden[-1, :, :]\n        out = self.fc(out)\n        return out\n\n","metadata":{"id":"nQTNE4nfiEoq","execution":{"iopub.status.busy":"2024-07-01T15:02:57.301463Z","iopub.execute_input":"2024-07-01T15:02:57.301828Z","iopub.status.idle":"2024-07-01T15:02:57.308409Z","shell.execute_reply.started":"2024-07-01T15:02:57.301798Z","shell.execute_reply":"2024-07-01T15:02:57.307444Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{"id":"ieL05Sm5iEoq"}},{"cell_type":"code","source":"parser = argparse.ArgumentParser(description='設定資料與訓練參數')\n\n# 資料參數\nparser.add_argument('--concat_nframes', type=int, default=3,\n                    help='連接的幀數，n 必須為奇數 (總共 2k+1 = n 幀)')\nparser.add_argument('--train_ratio', type=float, default=0.75,\n                    help='訓練資料比例，其餘將用於驗證')\n\n# 訓練參數\nparser.add_argument('--seed', type=int, default=1213,\n                    help='隨機種子')\nparser.add_argument('--batch_size', type=int, default=512,\n                    help='批次大小')\nparser.add_argument('--num_epoch', type=int, default=10,\n                    help='訓練的 epoch 數量')\nparser.add_argument('--learning_rate', type=float, default=1e-4,\n                    help='學習率')\nparser.add_argument('--model_path', type=str, default='./model.ckpt',\n                    help='模型儲存的路徑')\n\n# 模型參數\nparser.add_argument('--input_dim', type=int, default=39 * 3,\n                    help='模型的輸入維度，不應更改此值')\nparser.add_argument('--hidden_layers', type=int, default=2,\n                    help='隱藏層的層數')\nparser.add_argument('--hidden_dim', type=int, default=64,\n                    help='隱藏層的維度')\n\nargs = parser.parse_args()\n\n# 打印參數設定\nprint('資料參數:')\nprint(f'- 連接的幀數: {args.concat_nframes}')\nprint(f'- 訓練資料比例: {args.train_ratio}')\n\nprint('\\n訓練參數:')\nprint(f'- 隨機種子: {args.seed}')\nprint(f'- 批次大小: {args.batch_size}')\nprint(f'- 訓練 epoch 數量: {args.num_epoch}')\nprint(f'- 學習率: {args.learning_rate}')\nprint(f'- 模型儲存路徑: {args.model_path}')\n\nprint('\\n模型參數:')\nprint(f'- 輸入維度: {args.input_dim}')\nprint(f'- 隱藏層數量: {args.hidden_layers}')\nprint(f'- 隱藏層維度: {args.hidden_dim}')","metadata":{"execution":{"iopub.status.busy":"2024-06-30T03:54:41.215171Z","iopub.execute_input":"2024-06-30T03:54:41.215896Z","iopub.status.idle":"2024-06-30T03:54:41.230742Z","shell.execute_reply.started":"2024-06-30T03:54:41.215866Z","shell.execute_reply":"2024-06-30T03:54:41.229363Z"},"id":"-z-OoY9XiEoq","outputId":"708b9599-8590-4cc1-c8c4-6c77c69f9a75","trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"usage: ipykernel_launcher.py [-h] [--concat_nframes CONCAT_NFRAMES]\n                             [--train_ratio TRAIN_RATIO] [--seed SEED]\n                             [--batch_size BATCH_SIZE] [--num_epoch NUM_EPOCH]\n                             [--learning_rate LEARNING_RATE]\n                             [--model_path MODEL_PATH] [--input_dim INPUT_DIM]\n                             [--hidden_layers HIDDEN_LAYERS]\n                             [--hidden_dim HIDDEN_DIM]\nipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-ff0d29ad-f3d0-4a4e-b9bb-889736b77981.json\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"],"ename":"SystemExit","evalue":"2","output_type":"error"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 7              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 10                # batch size\nnum_epoch = 50                   # the number of training epoch\nlearning_rate = 1e-4         # learning rate\nmodel_path = './model_2.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 6              # the number of hidden layers\nhidden_dim = input_dim//2             # the hidden dim","metadata":{"id":"79Nsdc9hiEoq","execution":{"iopub.status.busy":"2024-07-01T15:03:33.427797Z","iopub.execute_input":"2024-07-01T15:03:33.428153Z","iopub.status.idle":"2024-07-01T15:03:33.433713Z","shell.execute_reply.started":"2024-07-01T15:03:33.428123Z","shell.execute_reply":"2024-07-01T15:03:33.432791Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{"id":"6iAtZt3LiEoq"}},{"cell_type":"code","source":"same_seeds(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"id":"0-tWqXqliEoq","outputId":"8efc14e8-994b-43a4-baed-75884e8ed548","execution":{"iopub.status.busy":"2024-07-01T14:59:28.904965Z","iopub.execute_input":"2024-07-01T14:59:28.905542Z","iopub.status.idle":"2024-07-01T14:59:28.910525Z","shell.execute_reply.started":"2024-07-01T14:59:28.905510Z","shell.execute_reply":"2024-07-01T14:59:28.909618Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"DEVICE: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# preprocess data\ntrain_X, train_y = preprocess_data(split='train',\n                                   feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                                   phone_path='/kaggle/input/libraphone/libriphone',\n                                   concat_nframes=concat_nframes,\n                                   train_ratio=train_ratio)\n\nval_X, val_y = preprocess_data(split='val',\n                               feat_dir='/kaggle/input/libraphone/libriphone/feat',\n                               phone_path='/kaggle/input/libraphone/libriphone',\n                               concat_nframes=concat_nframes,\n                               train_ratio=train_ratio)","metadata":{"id":"lBa3ub2iiEor","outputId":"452df553-07da-4f7c-c75d-ffb42ecf75f6","execution":{"iopub.status.busy":"2024-07-01T14:59:29.109509Z","iopub.execute_input":"2024-07-01T14:59:29.109760Z","iopub.status.idle":"2024-07-01T14:59:38.420224Z","shell.execute_reply.started":"2024-07-01T14:59:29.109738Z","shell.execute_reply":"2024-07-01T14:59:38.419266Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"[Dataset] - # phone classes: 41, number of utterances for train: 2571\n","output_type":"stream"},{"name":"stderr","text":"2571it [00:06, 387.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\ntorch.Size([2571, 30000, 273])\ntorch.Size([2571, 30000])\n[Dataset] - # phone classes: 41, number of utterances for val: 858\n","output_type":"stream"},{"name":"stderr","text":"858it [00:01, 464.48it/s]","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\ntorch.Size([858, 30000, 273])\ntorch.Size([858, 30000])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)","metadata":{"id":"IpXuVwhviEor","execution":{"iopub.status.busy":"2024-07-01T14:59:44.366550Z","iopub.execute_input":"2024-07-01T14:59:44.367175Z","iopub.status.idle":"2024-07-01T14:59:44.371674Z","shell.execute_reply.started":"2024-07-01T14:59:44.367142Z","shell.execute_reply":"2024-07-01T14:59:44.370732Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()","metadata":{"id":"UoBt0eXPiEor","outputId":"c882c119-5c8d-4abe-9b24-008c6a35731a","execution":{"iopub.status.busy":"2024-07-01T14:59:44.578665Z","iopub.execute_input":"2024-07-01T14:59:44.579497Z","iopub.status.idle":"2024-07-01T14:59:44.884097Z","shell.execute_reply.started":"2024-07-01T14:59:44.579454Z","shell.execute_reply":"2024-07-01T14:59:44.883031Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"3905"},"metadata":{}}]},{"cell_type":"code","source":"# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"id":"ckZN5Nu0iEor","execution":{"iopub.status.busy":"2024-07-01T15:03:39.476738Z","iopub.execute_input":"2024-07-01T15:03:39.477126Z","iopub.status.idle":"2024-07-01T15:03:39.481890Z","shell.execute_reply.started":"2024-07-01T15:03:39.477096Z","shell.execute_reply":"2024-07-01T15:03:39.480993Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-07-01T15:03:40.745987Z","iopub.execute_input":"2024-07-01T15:03:40.746329Z","iopub.status.idle":"2024-07-01T15:03:40.925552Z","shell.execute_reply.started":"2024-07-01T15:03:40.746294Z","shell.execute_reply":"2024-07-01T15:03:40.924640Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 30000, 273])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"-dZmD4ZHiEor"}},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"id":"sxHS8GhKiEor","outputId":"2df2d2f8-5513-4343-9146-e0338f28b8d3","execution":{"iopub.status.busy":"2024-07-01T15:06:30.309644Z","iopub.execute_input":"2024-07-01T15:06:30.310305Z","iopub.status.idle":"2024-07-01T15:06:30.495300Z","shell.execute_reply.started":"2024-07-01T15:06:30.310271Z","shell.execute_reply":"2024-07-01T15:06:30.494276Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 30000, 273])"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(train_loader))[1].shape","metadata":{"id":"YP5rQe5XiEor","outputId":"15ca8efb-c11a-4829-a628-ec3a8db71e39","execution":{"iopub.status.busy":"2024-07-01T15:06:31.500592Z","iopub.execute_input":"2024-07-01T15:06:31.501307Z","iopub.status.idle":"2024-07-01T15:06:31.679364Z","shell.execute_reply.started":"2024-07-01T15:06:31.501267Z","shell.execute_reply":"2024-07-01T15:06:31.678477Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"torch.Size([10, 30000])"},"metadata":{}}]},{"cell_type":"code","source":"# create model, define a loss function, and optimizer\nmodel = RNN(input_dim=input_dim, hidden_dim=hidden_dim).to(device)\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","metadata":{"id":"qKUmwK-ziEor","execution":{"iopub.status.busy":"2024-07-01T15:04:55.933370Z","iopub.execute_input":"2024-07-01T15:04:55.933755Z","iopub.status.idle":"2024-07-01T15:04:55.942987Z","shell.execute_reply.started":"2024-07-01T15:04:55.933723Z","shell.execute_reply":"2024-07-01T15:04:55.942148Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"len(train_loader.dataset), len(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T15:18:08.336036Z","iopub.execute_input":"2024-06-29T15:18:08.336632Z","iopub.status.idle":"2024-06-29T15:18:08.343174Z","shell.execute_reply.started":"2024-06-29T15:18:08.336581Z","shell.execute_reply":"2024-06-29T15:18:08.342093Z"},"id":"wP4wDIpLiEor","outputId":"d81cbebc-59b3-467b-8e55-b09826eec416","trusted":true},"execution_count":null,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(1588590, 3103)"},"metadata":{}}]},{"cell_type":"code","source":"def train(model: torch.nn.Module,\n          data_loader: torch.utils.data.DataLoader,\n          loss_fn: torch.nn.Module,\n          optimizer: torch.optim.Optimizer,\n          device: torch.device):\n    model.train()\n    train_acc = 0.0\n    train_loss = 0.0\n    for features, labels in tqdm(data_loader):\n        features, labels = features.to(device), labels.to(device)\n        # 1. Froward pass\n        outputs = model(features)[:, 0]\n\n         # 2. Calculate loss\n        loss = loss_fn(outputs, labels)\n\n        # 3. Optimizer zer grade\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. optimizer step\n        optimizer.step()\n\n        _, train_pred = torch.max(outputs, 1)\n        train_acc += (train_pred == labels).sum().item()\n        train_loss += loss.item()\n\n    return train_acc / len(data_loader.dataset), train_loss / len(data_loader) #data_loader.dataset total sample size and data_loader batch size\n\ndef validate(model: torch.nn.Module,\n             data_loader: torch.utils.data.DataLoader,\n             loss_fn: torch.nn.Module,\n             device: torch.device):\n    model.eval()\n    val_acc = 0.0\n    val_loss = 0.0\n    with torch.no_grad():\n        for features, labels in tqdm(data_loader):\n            features, labels = features.to(device), labels.to(device)\n\n            outputs = model(features)\n            loss = loss_fn(outputs, labels)\n\n            _, val_pred = torch.max(outputs, 1)\n            val_acc += (val_pred == labels).sum().item()\n            val_loss += loss.item()\n\n    return val_acc / len(data_loader.dataset), val_loss / len(data_loader)\n\n\n# Main training loop\nbest_acc = 0.0\ntrain_info = {\n    \"Acc\":[],\n    \"Loss\":[]\n}\nval_info = {\n    \"Acc\":[],\n    \"Loss\":[]\n}\nfor epoch in range(num_epoch):\n    train_acc, train_loss = train(model, train_loader, criterion, optimizer, device)\n    val_acc, val_loss = validate(model, val_loader, criterion, device)\n    train_info[\"Acc\"].append(train_acc)\n    train_info[\"Loss\"].append(train_loss)\n    val_info[\"Acc\"].append(val_acc)\n    val_info[\"Loss\"].append(val_loss)\n    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc:.5f} Loss: {train_loss:.5f} | Val Acc: {val_acc:.5f} Loss: {val_loss:.5f}')\n\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), model_path)\n        print(f'Saving model with acc {best_acc:.5f}')\n","metadata":{"id":"SB3CSK3fiEos","outputId":"601a4834-46f7-4aa7-f793-ea4aee0d971a","execution":{"iopub.status.busy":"2024-07-01T15:06:08.553252Z","iopub.execute_input":"2024-07-01T15:06:08.553992Z","iopub.status.idle":"2024-07-01T15:06:09.003749Z","shell.execute_reply.started":"2024-07-01T15:06:08.553959Z","shell.execute_reply":"2024-07-01T15:06:09.002512Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stderr","text":"  0%|          | 0/258 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 64\u001b[0m\n\u001b[1;32m     59\u001b[0m val_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]\n\u001b[1;32m     62\u001b[0m }\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[0;32m---> 64\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[1;32m     66\u001b[0m     train_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_acc)\n","Cell \u001b[0;32mIn[90], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(features)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m  \u001b[38;5;66;03m# 2. Calculate loss\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 3. Optimizer zer grade\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3113\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3111\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3116\u001b[0m     )\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n","\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([10, 30000])) that is different to the input size (torch.Size([10])) is deprecated. Please ensure they have the same size."],"ename":"ValueError","evalue":"Using a target size (torch.Size([10, 30000])) that is different to the input size (torch.Size([10])) is deprecated. Please ensure they have the same size.","output_type":"error"}]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Plotting the results with Seaborn\nepochs = range(1, num_epoch + 1)\n\nsns.set(style='whitegrid')\n\nplt.figure(figsize=(12, 5))\n\n# Plot accuracy\nplt.subplot(1, 2, 1)\nsns.lineplot(x=epochs, y=train_info[\"Acc\"], label='Training Accuracy')\nsns.lineplot(x=epochs, y=val_info[\"Acc\"], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nsns.lineplot(x=epochs, y=train_info[\"Loss\"], label='Training Loss')\nsns.lineplot(x=epochs, y=val_info[\"Loss\"], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"Model_2.png\")\nplt.show()","metadata":{"id":"WbR2iOn8iEos","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare Result with different Model","metadata":{"id":"OyER49VRiEos"}},{"cell_type":"markdown","source":"**Base**\n\n![image.png](attachment:4373f474-b07f-440e-a058-994c20029480.png)","metadata":{"id":"gWKkJqUxiEos"}},{"cell_type":"markdown","source":"**Narrow and Depper**\n\n![image.png](attachment:435d6720-2070-4b29-b475-b3e0ed267965.png)\n\n*Notes*\n- Starting over fitting after 7tg or 8th epochs.","metadata":{"id":"O93enyuLiEos"}},{"cell_type":"markdown","source":"**wider and shallower**\n\nTypical disadvantage of wide and shallow model:\n- Computational Complexity:\n    >A wide and shallow network with a vast number of input neurons can result in high computational complexity. Training and making predictions with such networks may be computationally expensive, especially as the number of **parameters increases**.\n- Overfitting:\n    >Shallow networks may struggle with capturing complex patterns in the data. The model might end up fitting the training data too closely, leading to overfitting. Overfitting occurs when the model performs well on training data but poorly on unseen data.\n- Limited Representational Power:\n    >Shallow networks might not have enough depth to learn hierarchical representations of features in the data. Deep networks, with multiple hidden layers, are often better suited for **capturing intricate relationships and representations**.\n- Feature Extraction Challenges:\n    >Wide and shallow networks may face challenges in automatic feature extraction. Deep networks, by design, learn hierarchical features from data, allowing them to automatically **extract and represent meaningful features**.\n\n\n![image.png](attachment:9ae31e8c-b189-43ba-a3d7-5975f33760c5.png)\n\n*Notes*\n\n- Here, we only see the time of training is longer than deeper model, which we train last.","metadata":{"id":"gDbo0dD2iEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.25**\n\n![image.png](attachment:90438905-0288-4be4-ae0b-867881d5fe62.png)\n\n*Notes*\n\n- Because the train set and validation set are not that overlap when we trained, it seems not that easy to overfitting.","metadata":{"id":"jLbuE2gciEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.5**\n\n![image.png](attachment:7255f60f-393c-4198-b659-0ee5f049a34e.png)\n\n*Notes*\n\n- As we increse the rate, we see it more flater after 20 epochs than 0.25 rate","metadata":{"id":"Z0OYnisZiEos"}},{"cell_type":"markdown","source":"**Drop out rate 0.75**\n\n![image.png](attachment:30e85442-34c5-4aa9-b00f-fba859cf4dfc.png)\n\n*Notes*\n\n- A big problem is we increse the rate to prevent over fitting, but it will under fitting.\n\n*Insights*\n\n- We can use deeper and narrow model and deop out to train model.","metadata":{"id":"Uqzds3R8iEos"}},{"cell_type":"markdown","source":"**drop out rate 0.5 and deep + narrow model**\n\n![image.png](attachment:c4387e4f-4531-4d98-aae8-9de0a9372758.png)\n\n*Notes*\n\n- It doesn't overfitting and the accuracy is the highest so far.","metadata":{"id":"_Wrt7OqAiEot"}},{"cell_type":"markdown","source":"**BN -> ReLU -> Dropout**\n\n![image.png](attachment:23920f65-b5b6-4744-9f59-4d0cc2933674.png)","metadata":{"id":"5oT1CAvbiEot"}},{"cell_type":"markdown","source":"**Linear -> ReLU -> Dropout -> BN -> Linear**\n\n![image.png](attachment:6cfd7444-53aa-4525-ad26-6d4995591b4e.png)","metadata":{"id":"B79KaRfOiEot"}},{"cell_type":"markdown","source":"**Concat 5**\n\n![image.png](attachment:3694e598-a193-41f6-ba8a-fd94f7cbe236.png)","metadata":{"id":"DMhV_IN9iEot"}},{"cell_type":"markdown","source":"**Concat 7**\n\n![image.png](attachment:2801749b-0b7d-4761-91e9-ad3883eac6ba.png)","metadata":{"id":"rIMMj5XeiEot"}},{"cell_type":"code","source":"","metadata":{"id":"Za_gF1UziEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_-eDHEVmiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"D4ptYamsiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"HawFQRBNiEot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"oLFegT1hiEot"},"execution_count":null,"outputs":[]}]}