{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3936,"databundleVersionId":137277,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\n*Overview*\n\nThis competition asked to predict the forest cover type (the predominant kind of tree cover) using strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were derived from data obtained from the US Geological Survey (USGS) and USFS. The data is in raw form (not scaled) and contains binary columns for qualitative independent variables such as wilderness areas and soil type.\n\n*Study Area*\n\nThe study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, meaning existing forest cover types are more a result of ecological processes rather than forest management practices.\n\n*Dataset Description*\n\nThe study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. \n\n- The seven types are:\n\n    1. Spruce/Fir\n    2. Lodgepole Pine\n    3. Ponderosa Pine\n    4. Cottonwood/Willow\n    5. Aspen\n    6. Douglas-fir\n    7. Krummholz\n    \n    \n- Data Fields:\n\n    1. Elevation: Elevation in meters\n    2. Aspect: Aspect in degrees azimuth\n    3. Slope: Slope in degrees\n    4. Horizontal_Distance_To_Hydrology: Horizontal distance to nearest surface water features\n    5. Vertical_Distance_To_Hydrology: Vertical distance to nearest surface water features\n    6. Horizontal_Distance_To_Roadways: Horizontal distance to nearest roadway\n    7. Hillshade_9am (0 to 255 index): Hillshade index at 9am, summer solstice\n    8. Hillshade_Noon (0 to 255 index): Hillshade index at noon, summer solstice\n    9. Hillshade_3pm (0 to 255 index): Hillshade index at 3pm, summer solstice\n    10. Horizontal_Distance_To_Fire_Points: Horizontal distance to nearest wildfire ignition points\n    11. Wilderness_Area (4 binary columns, 0 = absence or 1 = presence): Wilderness area designation\n    12. Soil_Type (40 binary columns, 0 = absence or 1 = presence): Soil type designation\n    13. Cover_Type (7 types, integers 1 to 7): Forest cover type designation\n    \n","metadata":{}},{"cell_type":"markdown","source":"> Wilderness Areas\n\n1. Rawah Wilderness Area\n2. Neota Wilderness Area\n3. Comanche Peak Wilderness Area\n4. Cache la Poudre Wilderness Area\n    \n    \n>Soil Types\n\n1. Cathedral family - Rock outcrop complex, extremely stony\n2. Vanet - Ratake families complex, very stony\n3. Haploborolis - Rock outcrop complex, rubbly\n4. Ratake family - Rock outcrop complex, rubbly\n5. Vanet family - Rock outcrop complex, rubbly\n6. Vanet - Wetmore families - Rock outcrop complex, stony\n    \n    \n    \n>Gothic family\n\n1. Supervisor - Limber families complex\n2. Troutville family, very stony\n3. Bullwark - Catamount families - Rock outcrop complex, rubbly\n4. Bullwark - Catamount families - Rock land complex, rubbly\n5. Legault family - Rock land complex, stony\n6. Catamount family - Rock land - Bullwark family complex, rubbly\n7. Pachic Argiborolis - Aquolis complex\n8. Unspecified in the USFS Soil and ELU Survey\n9. Cryaquolis - Cryoborolis complex\n10. Gateview family - Cryaquolis complex\n11. Rogert family, very stony\n12. Typic Cryaquolis - Borohemists complex\n13. Typic Cryaquepts - Typic Cryaquolls complex\n14. Typic Cryaquolls - Leighcan family, till substratum complex\n15. Leighcan family, till substratum, extremely bouldery\n16. Leighcan family, till substratum - Typic Cryaquolls complex\n17. Leighcan family, extremely stony\n18. Leighcan family, warm, extremely stony\n19. Granile - Catamount families complex, very stony\n20. Leighcan family, warm - Rock outcrop complex, extremely stony\n21. Leighcan family - Rock outcrop complex, extremely stony\n22. Como - Legault families complex, extremely stony\n23. Como family - Rock land - Legault family complex, extremely stony\n24. Leighcan - Catamount families complex, extremely stony\n25. Catamount family - Rock outcrop - Leighcan family complex, extremely stony\n26. Leighcan - Catamount families - Rock outcrop complex, extremely stony\n27. Cryorthents - Rock land complex, extremely stony\n28. Cryumbrepts - Rock outcrop - Cryaquepts complex\n29. Bross family - Rock land - Cryumbrepts complex, extremely stony\n30. Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony\n31. Leighcan - Moran families - Cryaquolls complex, extremely stony\n32. Moran family - Cryorthents - Leighcan family complex, extremely stony\n33. Moran family - Cryorthents - Rock land complex, extremely stony\n","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Target Problem\n\nThe training set (15,120 observations) contains both features and the Cover_Type. The test set contains only the features. You must predict the Cover_Type for every row in the test set (565,892 observations).\n\n","metadata":{}},{"cell_type":"markdown","source":"**Evaluation**\n\nSubmissions are evaluated on **multi-class classification accuracy**.\n","metadata":{}},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install chardet\n!pip install plotly","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:33:28.642059Z","iopub.execute_input":"2024-06-20T14:33:28.642486Z","iopub.status.idle":"2024-06-20T14:34:03.887641Z","shell.execute_reply.started":"2024-06-20T14:33:28.642456Z","shell.execute_reply":"2024-06-20T14:34:03.886308Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting chardet\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: chardet\nSuccessfully installed chardet-5.2.0\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.18.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.2.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly) (3.1.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom pathlib import Path\nimport os\nimport chardet\nimport requests\nimport itertools\n\nimport time\n\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:34:03.890008Z","iopub.execute_input":"2024-06-20T14:34:03.890421Z","iopub.status.idle":"2024-06-20T14:34:04.532475Z","shell.execute_reply.started":"2024-06-20T14:34:03.890382Z","shell.execute_reply":"2024-06-20T14:34:04.531218Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"*Visualize*","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# Seaborn\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\n\n\n# Plotly\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\n#mlxtend\nfrom mlxtend.plotting import scatterplotmatrix\nfrom mlxtend.plotting import heatmap","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:34:04.533953Z","iopub.execute_input":"2024-06-20T14:34:04.534471Z","iopub.status.idle":"2024-06-20T14:34:07.853053Z","shell.execute_reply.started":"2024-06-20T14:34:04.534440Z","shell.execute_reply":"2024-06-20T14:34:07.851494Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"*Sklearn and Model*","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.utils import resample\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n#Feature selection\nfrom sklearn.feature_selection import mutual_info_classif, SelectFromModel, RFE, RFECV, SelectKBest, chi2\n\n#Model selection\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_val_score\n\n#Model pipe\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\n#Preprocessing\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, label_binarize\nfrom imblearn.over_sampling import SMOTE\n\n#Model\nimport xgboost as xgb\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#Evalution\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\nfrom sklearn.tree import plot_tree ","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:34:07.855677Z","iopub.execute_input":"2024-06-20T14:34:07.856665Z","iopub.status.idle":"2024-06-20T14:34:31.421485Z","shell.execute_reply.started":"2024-06-20T14:34:07.856618Z","shell.execute_reply":"2024-06-20T14:34:31.419908Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-20 14:34:13.642424: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-20 14:34:13.642596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-20 14:34:13.902865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"class LoadingFile():\n    def __init__(self, path, name, url=None):\n        self.path = path\n        self.name = name\n        self.url = url\n\n    def size(self):\n        kib = 1024\n        size = os.path.getsize(Path(self.path))\n        print(f\"{self.name} size: {np.round(size / kib)} Kib\")\n\n    def Encoding_predict(self):\n        file_path = Path(self.path)\n        with open(file_path, 'rb') as f:\n            contents = f.read()\n\n        encoding_info = chardet.detect(contents)\n\n        detected_encoding = encoding_info['encoding']\n        confidence = encoding_info['confidence']\n\n        print(f\"File name: {self.name:<25}\\nEncoding: {detected_encoding:<10}Confidence: {confidence}\")\n\n\n    def download_data(self):\n        data_path = Path(self.path)\n        if data_path.is_dir():\n            print(f\"{data_path} directory exist.\")\n        else:\n            print(f\"Creating {data_path}\")\n            data_path.mkdir(parents=True, exist_ok=True)\n\n        if (data_path / Path(self.name)).exists():\n            print(f\"{self.name} already exist\")\n            pass\n        else:\n            with open(data_path / self.name, \"wb\") as f:\n                req = requests.get(self.url)\n                print(\"Downloading data...\")\n                f.write(req.content)\n                print(\"Done!\")\nname=[]\npath = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        name.append(filename)\n        path.append(os.path.join(dirname, filename))\n\n        print(f\"Path: {dirname} | Data_Name: {filename}\")\n        size = LoadingFile(os.path.join(dirname, filename), filename).size()\n        print()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T14:34:31.424040Z","iopub.execute_input":"2024-06-20T14:34:31.425267Z","iopub.status.idle":"2024-06-20T14:34:31.460642Z","shell.execute_reply.started":"2024-06-20T14:34:31.425207Z","shell.execute_reply":"2024-06-20T14:34:31.459195Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Path: /kaggle/input/forest-cover-type-prediction | Data_Name: train.csv.zip\ntrain.csv.zip size: 333.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: sampleSubmission.csv\nsampleSubmission.csv size: 4891.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: sampleSubmission.csv.zip\nsampleSubmission.csv.zip size: 1218.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: test3.csv\ntest3.csv size: 0.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: train.csv\ntrain.csv size: 1982.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: test.csv\ntest.csv size: 74185.0 Kib\n\nPath: /kaggle/input/forest-cover-type-prediction | Data_Name: test.csv.zip\ntest.csv.zip size: 11767.0 Kib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#LoadingFile(path[0], name[0]).size()\n#LoadingFile(path[1], name[1]).size()","metadata":{},"execution_count":null,"outputs":[]}]}